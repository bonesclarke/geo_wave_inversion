{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89afe857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e97f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9001a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for data loading and preparation\n",
    "def map_seismic_to_velocity_path(input_file):\n",
    "    \"\"\"Convert seismic data path to velocity model path\"\"\"\n",
    "    return Path(str(input_file).replace('seis', 'vel').replace('data', 'model'))\n",
    "\n",
    "def get_train_files(data_path):\n",
    "    \"\"\"Find all seismic data files and map to velocity model files\"\"\"\n",
    "    # Find all seismic data files (containing 'seis' or 'data' in filename)\n",
    "    input_files = [\n",
    "        f for f in Path(data_path).rglob('*.npy')\n",
    "        if ('seis' in f.stem) or ('data' in f.stem)\n",
    "    ]\n",
    "    \n",
    "    # Map each input file to its corresponding output file\n",
    "    output_files = [map_seismic_to_velocity_path(f) for f in input_files]\n",
    "    \n",
    "    # Verify all output files exist\n",
    "    missing_files = [f for f in output_files if not f.exists()]\n",
    "    if missing_files:\n",
    "        raise FileNotFoundError(f\"Missing velocity model files: {missing_files[:5]}...\")\n",
    "    \n",
    "    return input_files, output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved dataset classes with normalization\n",
    "class SeismicDataset(Dataset):\n",
    "    def __init__(self, inputs_files, output_files, n_examples_per_file=500, normalize=True, transform=None):\n",
    "        assert len(inputs_files) == len(output_files)\n",
    "        self.inputs_files = inputs_files\n",
    "        self.output_files = output_files\n",
    "        self.n_examples_per_file = n_examples_per_file\n",
    "        self.normalize = normalize\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Calculate normalization statistics if needed\n",
    "        if normalize:\n",
    "            self.input_stats, self.output_stats = self._calculate_stats()\n",
    "\n",
    "    def _calculate_stats(self):\n",
    "        \"\"\"Calculate mean and std for normalization\"\"\"\n",
    "        # Sample a subset of files to calculate statistics\n",
    "        input_means, input_stds = [], []\n",
    "        output_means, output_stds = [], []\n",
    "        \n",
    "        sample_size = min(10, len(self.inputs_files))\n",
    "        \n",
    "        print(f\"Calculating statistics from {sample_size} files...\")\n",
    "        for i in range(sample_size):\n",
    "            X = np.load(self.inputs_files[i])\n",
    "            y = np.load(self.output_files[i])\n",
    "            \n",
    "            # Calc stats for input\n",
    "            input_means.append(np.mean(X))\n",
    "            input_stds.append(np.std(X))\n",
    "            \n",
    "            # Calc stats for output\n",
    "            output_means.append(np.mean(y))\n",
    "            output_stds.append(np.std(y))\n",
    "        \n",
    "        input_mean = np.mean(input_means)\n",
    "        input_std = np.std(input_stds) if np.std(input_stds) > 0 else 1.0\n",
    "        output_mean = np.mean(output_means)\n",
    "        output_std = np.std(output_stds) if np.std(output_stds) > 0 else 1.0\n",
    "        \n",
    "        print(f\"Input stats - Mean: {input_mean:.4f}, Std: {input_std:.4f}\")\n",
    "        print(f\"Output stats - Mean: {output_mean:.4f}, Std: {output_std:.4f}\")\n",
    "        \n",
    "        return (input_mean, input_std), (output_mean, output_std)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_files) * self.n_examples_per_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate file offset and sample offset within file\n",
    "        file_idx = idx // self.n_examples_per_file\n",
    "        sample_idx = idx % self.n_examples_per_file\n",
    "    \n",
    "        X = np.load(self.inputs_files[file_idx], mmap_mode='r')\n",
    "        y = np.load(self.output_files[file_idx], mmap_mode='r')\n",
    "    \n",
    "        try:\n",
    "            X_sample, y_sample = X[sample_idx].copy(), y[sample_idx].copy()\n",
    "            \n",
    "            # Apply normalization if enabled\n",
    "            if self.normalize:\n",
    "                X_sample = (X_sample - self.input_stats[0]) / (self.input_stats[1] + 1e-8)\n",
    "                y_sample = (y_sample - self.output_stats[0]) / (self.output_stats[1] + 1e-8)\n",
    "            \n",
    "            # Apply any additional transforms\n",
    "            if self.transform:\n",
    "                X_sample, y_sample = self.transform(X_sample, y_sample)\n",
    "                \n",
    "            # Ensure contiguous memory layout to avoid negative stride issues\n",
    "            X_sample = np.ascontiguousarray(X_sample)\n",
    "            y_sample = np.ascontiguousarray(y_sample)\n",
    "                \n",
    "            # Convert to torch tensors\n",
    "            X_sample = torch.from_numpy(X_sample).float()\n",
    "            y_sample = torch.from_numpy(y_sample).float()\n",
    "                \n",
    "            return X_sample, y_sample\n",
    "        finally:\n",
    "            del X, y\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_files, normalize=True, input_stats=None):\n",
    "        self.test_files = test_files\n",
    "        self.normalize = normalize\n",
    "        self.input_stats = input_stats\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        test_file = self.test_files[i]\n",
    "        X = np.load(test_file)\n",
    "        \n",
    "        if self.normalize and self.input_stats:\n",
    "            X = (X - self.input_stats[0]) / (self.input_stats[1] + 1e-8)\n",
    "        \n",
    "        X = torch.from_numpy(X).float()\n",
    "        return X, test_file.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a204b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation class with fixed padding operation\n",
    "class SeismicAugmentation:\n",
    "    def __init__(self, \n",
    "                 flip_prob=0.5, \n",
    "                 noise_prob=0.3, \n",
    "                 noise_level=0.05,\n",
    "                 shift_prob=0.3,\n",
    "                 max_shift=5):\n",
    "        self.flip_prob = flip_prob\n",
    "        self.noise_prob = noise_prob\n",
    "        self.noise_level = noise_level\n",
    "        self.shift_prob = shift_prob\n",
    "        self.max_shift = max_shift\n",
    "\n",
    "    def __call__(self, X, y):\n",
    "        # Make a copy to avoid modifying the original data\n",
    "        X = X.copy()\n",
    "        y = y.copy()\n",
    "        \n",
    "        # Horizontal flip\n",
    "        if np.random.random() < self.flip_prob:\n",
    "            X = np.flip(X, axis=1).copy()  # Use np.flip and make a copy to avoid negative strides\n",
    "            y = np.flip(y, axis=1).copy()  # Use np.flip and make a copy to avoid negative strides\n",
    "        \n",
    "        # Add random noise to input\n",
    "        if np.random.random() < self.noise_prob:\n",
    "            noise = np.random.normal(0, self.noise_level, X.shape)\n",
    "            X = X + noise\n",
    "        \n",
    "        # Random time shift (along time axis, usually dim 0)\n",
    "        if np.random.random() < self.shift_prob:\n",
    "            shift = np.random.randint(-self.max_shift, self.max_shift + 1)\n",
    "            \n",
    "            # Only apply shift if it's non-zero\n",
    "            if shift != 0:\n",
    "                # Create padding dimensions based on the array's actual shape\n",
    "                pad_width = [(0, 0)] * X.ndim  # Initialize with no padding for all dimensions\n",
    "                \n",
    "                if shift > 0:\n",
    "                    # Pad at the beginning of the second dimension (columns/width)\n",
    "                    pad_width[1] = (shift, 0)\n",
    "                    X = np.pad(X, pad_width, mode='constant')[:, :-shift]\n",
    "                else:  # shift < 0\n",
    "                    # Pad at the end of the second dimension\n",
    "                    pad_width[1] = (0, -shift)\n",
    "                    X = np.pad(X, pad_width, mode='constant')[:, -shift:]\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f888f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
