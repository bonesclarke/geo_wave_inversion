{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T14:53:18.823481Z",
     "iopub.status.busy": "2025-04-25T14:53:18.823205Z",
     "iopub.status.idle": "2025-04-25T14:53:23.506381Z",
     "shell.execute_reply": "2025-04-25T14:53:23.505626Z",
     "shell.execute_reply.started": "2025-04-25T14:53:18.823463Z"
    }
   },
   "source": [
    "# Improved UNet pipepline with larger dataset - Copied Notebook with Modifications\n",
    "\n",
    "#### [<u>Initial version</u>](https://www.kaggle.com/code/egortrushin/gwi-improved-unet-pipepline-with-larger-dataset)\n",
    "\n",
    "- We used UNet model as introduced in [<u>5 depth U net with residual</u>](https://www.kaggle.com/code/adhok93/5-depth-u-net-with-residual) Notebook.\n",
    "- We used part of Full OpenWFI dataset, which was introduced in [<u>OpenFWI InversionNet Train with 670G Datasets</u>](https://www.kaggle.com/code/seshurajup/openfwi-inversionnet-train-with-670g-datasets) Notebook.\n",
    "\n",
    "#### <u>Copied version</u>\n",
    "\n",
    "- We will use openFWI dataset converted from float32 to float16 ([<u>openfwi_float16_1</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-1), [<u>openfwi_float16_2</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-2), and [<u>openfwi_float16_test</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-test)). Since reading of data from disk is a bottleneck here, the conversion allows us to read data from disk twice faster and to use twice more data in training for the same runtime.\n",
    "\n",
    "#### <u>Added Processing version</u>\n",
    "\n",
    "- I have added denoising and normalization to see if "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:02.356186Z",
     "iopub.status.busy": "2025-05-14T16:28:02.355913Z",
     "iopub.status.idle": "2025-05-14T16:28:02.366251Z",
     "shell.execute_reply": "2025-05-14T16:28:02.365259Z",
     "shell.execute_reply.started": "2025-05-14T16:28:02.356159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "data_path: /input\n",
    "model: \n",
    "    name: UNet\n",
    "    unet_params:\n",
    "        init_features: 32\n",
    "        depth: 5\n",
    "read_weights: null\n",
    "batch_size: 32\n",
    "print_freq: 1000\n",
    "max_epochs: 30\n",
    "es_epochs: 4\n",
    "seed: 42\n",
    "valid_frac: 16\n",
    "train_frac: 2\n",
    "optimizer:\n",
    "    lr: 0.0005\n",
    "    weight_decay: 0.001\n",
    "scheduler:\n",
    "    params:\n",
    "        factor: 0.316227766\n",
    "        patience: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, filtfilt, sosfilt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_sharing_strategy('file_system')\n",
    "\n",
    "# Utilities\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:02.367961Z",
     "iopub.status.busy": "2025-05-14T16:28:02.367746Z",
     "iopub.status.idle": "2025-05-14T16:28:06.750047Z",
     "shell.execute_reply": "2025-05-14T16:28:06.749262Z",
     "shell.execute_reply.started": "2025-05-14T16:28:02.367942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "def inputs_files_to_output_files(input_files):\n",
    "    return [\n",
    "        Path(str(f).replace('seis', 'vel').replace('data', 'model'))\n",
    "        for f in input_files\n",
    "    ]\n",
    "\n",
    "def get_train_files(data_path):\n",
    "\n",
    "    all_inputs = [\n",
    "        f\n",
    "        for f in\n",
    "        Path(data_path).rglob('*.npy')\n",
    "        if ('seis' in f.stem) or ('data' in f.stem)\n",
    "    ]\n",
    "\n",
    "    all_outputs = inputs_files_to_output_files(all_inputs)\n",
    "\n",
    "    assert all(f.exists() for f in all_outputs)\n",
    "\n",
    "    return all_inputs, all_outputs\n",
    "\n",
    "class SeismicDataset(Dataset):\n",
    "    def __init__(self, inputs_files, output_files, n_examples_per_file=500):\n",
    "        assert len(inputs_files) == len(output_files)\n",
    "        self.inputs_files = inputs_files\n",
    "        self.output_files = output_files\n",
    "        self.n_examples_per_file = n_examples_per_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_files) * self.n_examples_per_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate file offset and sample offset within file\n",
    "        file_idx = idx // self.n_examples_per_file\n",
    "        sample_idx = idx % self.n_examples_per_file\n",
    "\n",
    "        X = np.load(self.inputs_files[file_idx], mmap_mode='r')\n",
    "        y = np.load(self.output_files[file_idx], mmap_mode='r')\n",
    "\n",
    "        try:\n",
    "            return X[sample_idx].copy(), y[sample_idx].copy()\n",
    "        finally:\n",
    "            del X, y\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_files):\n",
    "        self.test_files = test_files\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        test_file = self.test_files[i]\n",
    "\n",
    "        return np.load(test_file), test_file.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:06.751541Z",
     "iopub.status.busy": "2025-05-14T16:28:06.751295Z",
     "iopub.status.idle": "2025-05-14T16:28:06.773854Z",
     "shell.execute_reply": "2025-05-14T16:28:06.773264Z",
     "shell.execute_reply.started": "2025-05-14T16:28:06.751525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class ResidualDoubleConv(nn.Module):\n",
    "    \"\"\"(Convolution => [BN] => ReLU) * 2 + Residual Connection\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "\n",
    "        # First convolution layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Second convolution layer\n",
    "        self.conv2 = nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Shortcut connection to handle potential channel mismatch\n",
    "        if in_channels == out_channels:\n",
    "            self.shortcut = nn.Identity()\n",
    "        else:\n",
    "            # Projection shortcut: 1x1 conv + BN to match output channels\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # Store the input for the residual connection\n",
    "\n",
    "        # First conv block\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # Second conv block (without final ReLU yet)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Apply shortcut to the identity path\n",
    "        identity_mapped = self.shortcut(identity)\n",
    "\n",
    "        # Add the residual connection\n",
    "        out += identity_mapped\n",
    "\n",
    "        # Apply final ReLU\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then ResidualDoubleConv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "            # Input to ResidualDoubleConv = channels from upsampled layer below + channels from skip connection\n",
    "            # Output of ResidualDoubleConv = desired output channels for this decoder stage\n",
    "            self.conv = ResidualDoubleConv(in_channels + out_channels, out_channels) # Use ResidualDoubleConv\n",
    "\n",
    "        else: # Using ConvTranspose2d\n",
    "            # ConvTranspose halves the channels: in_channels -> in_channels // 2\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            # Input channels to ResidualDoubleConv\n",
    "            conv_in_channels = in_channels // 2 # Channels after ConvTranspose\n",
    "            skip_channels = out_channels       # Channels from skip connection\n",
    "            total_in_channels = conv_in_channels + skip_channels\n",
    "            self.conv = ResidualDoubleConv(total_in_channels, out_channels) # Use ResidualDoubleConv\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # x1 is the feature map from the layer below (needs upsampling)\n",
    "        # x2 is the skip connection from the corresponding encoder layer\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        # Pad x1 if its dimensions don't match x2 after upsampling\n",
    "        # Input is CHW\n",
    "        diffY = x2.size(2) - x1.size(2)\n",
    "        diffX = x2.size(3) - x1.size(3)\n",
    "\n",
    "        # Pad format: (padding_left, padding_right, padding_top, padding_bottom)\n",
    "        x1 = F.pad(\n",
    "            x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2]\n",
    "        )\n",
    "\n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"1x1 Convolution for the output layer\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net architecture implementation with Residual Blocks\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_channels=5,\n",
    "        n_classes=1,\n",
    "        init_features=32,\n",
    "        depth=5, # number of pooling layers\n",
    "        bilinear=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.depth = depth\n",
    "\n",
    "        self.initial_pool = nn.AvgPool2d(kernel_size=(14, 1), stride=(14, 1))\n",
    "\n",
    "        # --- Encoder ---\n",
    "        self.encoder_convs = nn.ModuleList() # Store conv blocks\n",
    "        self.encoder_pools = nn.ModuleList() # Store pool layers\n",
    "\n",
    "        # Initial conv block (no pooling before it)\n",
    "        # Use ResidualDoubleConv for the initial convolution block\n",
    "        self.inc = ResidualDoubleConv(n_channels, init_features)\n",
    "        self.encoder_convs.append(self.inc)\n",
    "\n",
    "        current_features = init_features\n",
    "        for _ in range(depth):\n",
    "            # Define convolution block for this stage\n",
    "            conv = ResidualDoubleConv(current_features, current_features * 2)\n",
    "            # Define pooling layer for this stage\n",
    "            pool = nn.MaxPool2d(2)\n",
    "            self.encoder_convs.append(conv)\n",
    "            self.encoder_pools.append(pool)\n",
    "            current_features *= 2\n",
    "\n",
    "        # --- Bottleneck ---\n",
    "        # Use ResidualDoubleConv for the bottleneck\n",
    "        self.bottleneck = ResidualDoubleConv(current_features, current_features)\n",
    "\n",
    "        # --- Decoder ---\n",
    "        self.decoder_blocks = nn.ModuleList()\n",
    "        # Input features start from bottleneck output features\n",
    "        # Output features at each stage are halved\n",
    "        for _ in range(depth):\n",
    "            # Up block uses ResidualDoubleConv internally and handles channels\n",
    "            up_block = Up(current_features, current_features // 2, bilinear)\n",
    "            self.decoder_blocks.append(up_block)\n",
    "            current_features //= 2 # Halve features for next Up block input\n",
    "\n",
    "        # --- Output Layer ---\n",
    "        # Input features are the output features of the last Up block\n",
    "        self.outc = OutConv(current_features, n_classes)\n",
    "\n",
    "    def _pad_or_crop(self, x, target_h=70, target_w=70):\n",
    "        \"\"\"Pads or crops input tensor x to target height and width.\"\"\"\n",
    "        _, _, h, w = x.shape\n",
    "        # Pad Height if needed\n",
    "        if h < target_h:\n",
    "            pad_top = (target_h - h) // 2\n",
    "            pad_bottom = target_h - h - pad_top\n",
    "            x = F.pad(x, (0, 0, pad_top, pad_bottom))  # Pad height only\n",
    "            h = target_h\n",
    "        # Pad Width if needed\n",
    "        if w < target_w:\n",
    "            pad_left = (target_w - w) // 2\n",
    "            pad_right = target_w - w - pad_left\n",
    "            x = F.pad(x, (pad_left, pad_right, 0, 0))  # Pad width only\n",
    "            w = target_w\n",
    "        # Crop Height if needed\n",
    "        if h > target_h:\n",
    "            crop_top = (h - target_h) // 2\n",
    "            # Use slicing to crop\n",
    "            x = x[:, :, crop_top : crop_top + target_h, :]\n",
    "            h = target_h\n",
    "        # Crop Width if needed\n",
    "        if w > target_w:\n",
    "            crop_left = (w - target_w) // 2\n",
    "            x = x[:, :, :, crop_left : crop_left + target_w]\n",
    "            w = target_w\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial pooling and resizing\n",
    "        x_pooled = self.initial_pool(x)\n",
    "        x_resized = self._pad_or_crop(x_pooled, target_h=70, target_w=70)\n",
    "\n",
    "        # --- Encoder Path ---\n",
    "        skip_connections = []\n",
    "        xi = x_resized\n",
    "\n",
    "        # Apply initial conv (inc)\n",
    "        xi = self.encoder_convs[0](xi)\n",
    "        skip_connections.append(xi) # Store output of inc\n",
    "\n",
    "        # Apply subsequent encoder convs and pools\n",
    "        # self.depth is the number of pooling layers\n",
    "        for i in range(self.depth):\n",
    "            # Apply conv block for this stage\n",
    "            xi = self.encoder_convs[i+1](xi)\n",
    "            # Store skip connection *before* pooling\n",
    "            skip_connections.append(xi)\n",
    "            # Apply pooling layer for this stage\n",
    "            xi = self.encoder_pools[i](xi)\n",
    "\n",
    "        # Apply bottleneck conv\n",
    "        xi = self.bottleneck(xi)\n",
    "\n",
    "        # --- Decoder Path ---\n",
    "        xu = xi # Start with bottleneck output\n",
    "        # Iterate through decoder blocks and corresponding skip connections in reverse\n",
    "        for i, block in enumerate(self.decoder_blocks):\n",
    "            # Determine the correct skip connection index from the end\n",
    "            # Example: depth=5. Skips stored: [inc, enc1, enc2, enc3, enc4] (indices 0-4)\n",
    "            # Decoder 0 (Up(1024, 512)) needs skip 4 (enc4)\n",
    "            # Decoder 1 (Up(512, 256)) needs skip 3 (enc3) ...\n",
    "            # Decoder 4 (Up(64, 32)) needs skip 0 (inc)\n",
    "            skip_index = self.depth - 1 - i\n",
    "            skip = skip_connections[skip_index]\n",
    "            xu = block(xu, skip) # Up block combines xu (from below) and skip\n",
    "\n",
    "        # --- Final Output ---\n",
    "        logits = self.outc(xu)\n",
    "        # Apply scaling and offset specific to the problem's target range\n",
    "        output = logits * 1000.0 + 1500.0\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:06.775018Z",
     "iopub.status.busy": "2025-05-14T16:28:06.774813Z",
     "iopub.status.idle": "2025-05-14T16:28:06.800170Z",
     "shell.execute_reply": "2025-05-14T16:28:06.799440Z",
     "shell.execute_reply.started": "2025-05-14T16:28:06.775002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    \"\"\"Design a Butterworth bandpass filter.\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band', output='ba')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    \"\"\"Apply a Butterworth bandpass filter to a 1D signal.\"\"\"\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def denoise_seismic_with_bandpass(data, lowcut=0.004, highcut=0.3, fs=1.2, order=4):\n",
    "    \"\"\"\n",
    "    Apply Butterworth bandpass filter to seismic data.\n",
    "    Handles 2D, 3D, or 4D data.\n",
    "    Inner tqdm progress bars are disabled to reduce verbosity.\n",
    "    \"\"\"\n",
    "    original_shape = data.shape\n",
    "    \n",
    "    if len(original_shape) == 4: # 4D data (e.g., batch, channels, height, width)\n",
    "        denoised_data = np.zeros_like(data)\n",
    "        # Iterate through the first dimension (samples in batch)\n",
    "        for s_idx in tqdm(range(original_shape[0]), desc=\"Processing samples in batch\", leave=False, disable=True):\n",
    "            for c_idx in range(original_shape[1]): # Channels\n",
    "                denoised_data[s_idx, c_idx] = denoise_seismic_with_bandpass(\n",
    "                    data[s_idx, c_idx], lowcut, highcut, fs, order\n",
    "                )\n",
    "        return denoised_data\n",
    "    \n",
    "    elif len(original_shape) == 3: # 3D data (e.g., batch/channels, height, width)\n",
    "        denoised_data = np.zeros_like(data)\n",
    "        # Iterate through the first dimension (channels or slices)\n",
    "        for c_idx in tqdm(range(original_shape[0]), desc=\"Processing channels/slices\", leave=False, disable=True):\n",
    "            denoised_data[c_idx] = denoise_seismic_with_bandpass(\n",
    "                data[c_idx], lowcut, highcut, fs, order\n",
    "            )\n",
    "        return denoised_data\n",
    "    \n",
    "    elif len(original_shape) == 2: # 2D data (height, width) - filter per trace\n",
    "        denoised_data = np.zeros_like(data)\n",
    "        for i in range(data.shape[1]): # Iterate over traces (width)\n",
    "            trace = data[:, i]\n",
    "            # filtfilt requirement: signal length > 3 * filter order\n",
    "            if len(trace) > order * 3:\n",
    "                 denoised_data[:, i] = butter_bandpass_filter(trace, lowcut, highcut, fs, order)\n",
    "            else:\n",
    "                # To avoid verbose output, this warning is kept as a comment.\n",
    "                # print(f\"Warning: Trace length ({len(trace)}) for trace {i} too short for filter order ({order}). Copying original trace.\")\n",
    "                denoised_data[:, i] = trace\n",
    "        return denoised_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported data shape: {original_shape}. Expected 2D, 3D, or 4D.\")\n",
    "\n",
    "# Revised memory-efficient function with reduced print output\n",
    "def denoise_training_dataset_memory_efficient(train_loader, lowcut=0.004, highcut=0.3, fs=1.2, order=4):\n",
    "    denoised_inputs_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    print(\"Starting memory-efficient denoising process...\")\n",
    "    \n",
    "    try:\n",
    "        total_batches = len(train_loader)\n",
    "    except TypeError:\n",
    "        total_batches = None \n",
    "\n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    # This is the main progress bar the user will see, updating per batch\n",
    "    for inputs_batch, targets_batch in tqdm(train_loader, desc=\"Denoising batches\", total=total_batches, unit=\"batch\"):\n",
    "        inputs_batch_np = inputs_batch.numpy() \n",
    "        \n",
    "        denoised_batch = denoise_seismic_with_bandpass(\n",
    "            inputs_batch_np, lowcut=lowcut, highcut=highcut, fs=fs, order=order\n",
    "        )\n",
    "\n",
    "        denoised_inputs_list.append(denoised_batch)\n",
    "        targets_list.append(targets_batch.numpy()) \n",
    "    \n",
    "    overall_elapsed_time = time.time() - overall_start_time\n",
    "    # Adding a newline to ensure this print is on a new line after tqdm finishes\n",
    "    print(f\"\\nAll batches processed in {overall_elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    print(\"Concatenating denoised batches and targets...\")\n",
    "    concatenation_start_time = time.time()\n",
    "    \n",
    "    final_denoised_inputs = np.concatenate(denoised_inputs_list, axis=0)\n",
    "    final_targets = np.concatenate(targets_list, axis=0)\n",
    "    \n",
    "    concatenation_elapsed_time = time.time() - concatenation_start_time\n",
    "    print(f\"Concatenation completed in {concatenation_elapsed_time:.2f} seconds.\")\n",
    "    \n",
    "    return final_denoised_inputs, final_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a custom dataset that applies denoising on-the-fly\n",
    "class DenoisedSeismicDataset(Dataset):\n",
    "    def __init__(self, inputs_files, output_files, n_examples_per_file=500, \n",
    "                 apply_denoising=True, lowcut=0.004, highcut=0.3, fs=1.2, order=4):\n",
    "        assert len(inputs_files) == len(output_files)\n",
    "        self.inputs_files = inputs_files\n",
    "        self.output_files = output_files\n",
    "        self.n_examples_per_file = n_examples_per_file\n",
    "        self.apply_denoising = apply_denoising\n",
    "        self.lowcut = lowcut\n",
    "        self.highcut = highcut\n",
    "        self.fs = fs\n",
    "        self.order = order\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_files) * self.n_examples_per_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate file offset and sample offset within file\n",
    "        file_idx = idx // self.n_examples_per_file\n",
    "        sample_idx = idx % self.n_examples_per_file\n",
    "\n",
    "        X = np.load(self.inputs_files[file_idx], mmap_mode='r')\n",
    "        y = np.load(self.output_files[file_idx], mmap_mode='r')\n",
    "\n",
    "        try:\n",
    "            input_data = X[sample_idx].copy()\n",
    "            target_data = y[sample_idx].copy()\n",
    "            \n",
    "            # Apply denoising if enabled\n",
    "            if self.apply_denoising:\n",
    "                input_data = denoise_seismic_with_bandpass(\n",
    "                    input_data, \n",
    "                    lowcut=self.lowcut, \n",
    "                    highcut=self.highcut, \n",
    "                    fs=self.fs, \n",
    "                    order=self.order\n",
    "                )\n",
    "                \n",
    "            return input_data, target_data\n",
    "        finally:\n",
    "            del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check available disk space\n",
    "def check_available_disk_space(required_gb, save_dir):\n",
    "    \"\"\"Check if there's enough disk space available.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    disk_usage = shutil.disk_usage(save_dir)\n",
    "    available_gb = disk_usage.free / (1024**3)\n",
    "    \n",
    "    print(f\"Available disk space: {available_gb:.2f} GB\")\n",
    "    print(f\"Required disk space: {required_gb:.2f} GB\")\n",
    "    \n",
    "    return available_gb >= required_gb\n",
    "\n",
    "# Function to denoise and save the dataset\n",
    "def denoise_and_save_dataset(input_files, output_files, save_dir, \n",
    "                            lowcut=0.004, highcut=0.3, fs=1.2, order=4,\n",
    "                            prefix=\"train\"):\n",
    "    \"\"\"Process all files, apply denoising, and save to disk.\"\"\"\n",
    "    # Create directory for denoised data\n",
    "    denoised_dir = os.path.join(save_dir, \"denoised_data\")\n",
    "    os.makedirs(denoised_dir, exist_ok=True)\n",
    "    \n",
    "    # Estimate required disk space\n",
    "    sample_input = np.load(input_files[0], mmap_mode='r')\n",
    "    sample_size_bytes = sample_input.nbytes\n",
    "    total_files = len(input_files)\n",
    "    estimated_gb = (sample_size_bytes * total_files * 2) / (1024**3)  # x2 for inputs and targets\n",
    "    \n",
    "    # Check for sufficient disk space\n",
    "    if not check_available_disk_space(estimated_gb, save_dir):\n",
    "        raise RuntimeError(f\"Not enough disk space. Need approximately {estimated_gb:.2f} GB\")\n",
    "    \n",
    "    denoised_input_paths = []\n",
    "    target_output_paths = []\n",
    "    \n",
    "    print(f\"Processing {len(input_files)} files with prefix '{prefix}'...\")\n",
    "    \n",
    "    # Process each file\n",
    "    for i, (input_file, output_file) in enumerate(tqdm(zip(input_files, output_files), \n",
    "                                                      total=len(input_files),\n",
    "                                                      desc=f\"Denoising {prefix} files\")):\n",
    "        # Generate filenames\n",
    "        base_name = os.path.basename(input_file)\n",
    "        denoised_filename = f\"{prefix}_denoised_{i}_{base_name}\"\n",
    "        target_filename = f\"{prefix}_target_{i}_{os.path.basename(output_file)}\"\n",
    "        \n",
    "        denoised_path = os.path.join(denoised_dir, denoised_filename)\n",
    "        target_path = os.path.join(denoised_dir, target_filename)\n",
    "        \n",
    "        # Add to path lists\n",
    "        denoised_input_paths.append(denoised_path)\n",
    "        target_output_paths.append(target_path)\n",
    "        \n",
    "        # Skip if files already exist\n",
    "        if os.path.exists(denoised_path) and os.path.exists(target_path):\n",
    "            print(f\"Files already exist for {base_name}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Load data\n",
    "            input_data = np.load(input_file)\n",
    "            target_data = np.load(output_file)\n",
    "            \n",
    "            # Apply denoising\n",
    "            denoised_input = denoise_seismic_with_bandpass(\n",
    "                input_data, \n",
    "                lowcut=lowcut, \n",
    "                highcut=highcut, \n",
    "                fs=fs, \n",
    "                order=order\n",
    "            )\n",
    "            \n",
    "            # Save processed data\n",
    "            np.save(denoised_path, denoised_input)\n",
    "            np.save(target_path, target_data)\n",
    "            \n",
    "            # Free memory\n",
    "            del input_data, denoised_input, target_data\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {input_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return denoised_input_paths, target_output_paths\n",
    "\n",
    "# Dataset class for pre-denoised data\n",
    "class PreDenoisedSeismicDataset(Dataset):\n",
    "    def __init__(self, inputs_files, output_files, n_examples_per_file=250):\n",
    "        assert len(inputs_files) == len(output_files)\n",
    "        self.inputs_files = inputs_files\n",
    "        self.output_files = output_files\n",
    "        self.n_examples_per_file = n_examples_per_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_files) * self.n_examples_per_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate which file and sample within file\n",
    "        file_idx = idx // self.n_examples_per_file\n",
    "        sample_idx = idx % self.n_examples_per_file\n",
    "\n",
    "        try:\n",
    "            # Use memory-mapped loading for efficiency\n",
    "            X = np.load(self.inputs_files[file_idx], mmap_mode='r')\n",
    "            y = np.load(self.output_files[file_idx], mmap_mode='r')\n",
    "            \n",
    "            # Copy to avoid memory issues with mmap\n",
    "            input_data = X[sample_idx].copy()\n",
    "            target_data = y[sample_idx].copy()\n",
    "                \n",
    "            return torch.from_numpy(input_data).float(), torch.from_numpy(target_data).float()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx} from file {self.inputs_files[file_idx]}: {str(e)}\")\n",
    "            # Return zeros with appropriate shape (adjust based on your data dimensions)\n",
    "            return torch.zeros((1, 224, 224), dtype=torch.float32), torch.zeros((1, 224, 224), dtype=torch.float32)\n",
    "        finally:\n",
    "            # Clean up memory-mapped files\n",
    "            if 'X' in locals():\n",
    "                del X\n",
    "            if 'y' in locals():\n",
    "                del y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "def format_time(elapsed):\n",
    "    \"\"\"Take a time in seconds and return a string hh:mm:ss.\"\"\"\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def seed_everything(\n",
    "    seed_value: int\n",
    ") -> None:\n",
    "\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "    if torch.backends.cudnn.is_available:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4070 SUPER\n",
      "GPU memory: 11.99GB\n",
      "\n",
      "{'data_path': '/input', 'model': {'name': 'UNet', 'unet_params': {'init_features': 32, 'depth': 5}}, 'read_weights': None, 'batch_size': 32, 'print_freq': 1000, 'max_epochs': 30, 'es_epochs': 4, 'seed': 42, 'valid_frac': 16, 'train_frac': 2, 'optimizer': {'lr': 0.0005, 'weight_decay': 0.001}, 'scheduler': {'params': {'factor': 0.316227766, 'patience': 1}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "_, total = torch.cuda.mem_get_info(device=0)\n",
    "print(f\"GPU memory: {total / 1024**3:.2f}GB\")\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as file_obj:\n",
    "    config = yaml.safe_load(file_obj)\n",
    "print()\n",
    "print(config)\n",
    "if config[\"data_path\"] is None:\n",
    "    config[\"data_path\"] = os.environ[\"TMPDIR\"]\n",
    "    print(\"data_path:\", config[\"data_path\"])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input/output files: 960\n",
      "Number of train files: 450\n",
      "Number of valid files: 60\n"
     ]
    }
   ],
   "source": [
    "# Preparation and training\n",
    "# Refactored training pipeline with pre-denoising\n",
    "# Set random seed\n",
    "seed_everything(config[\"seed\"])\n",
    "\n",
    "# Get data files\n",
    "all_inputs, all_outputs = [], []\n",
    "for x in [\"input/train_samples\", \"input/openfwi_float16_1\", \"input/openfwi_float16_2\"]:\n",
    "    all_inputs1, all_outputs1 = get_train_files(x)\n",
    "    all_inputs.extend(all_inputs1)\n",
    "    all_outputs.extend(all_outputs1)\n",
    "print(\"Total number of input/output files:\", len(all_inputs))\n",
    "\n",
    "# Split into train and validation sets\n",
    "valid_indices = list(range(0, len(all_inputs), config[\"valid_frac\"]))\n",
    "valid_inputs = [all_inputs[i] for i in valid_indices]\n",
    "train_inputs = [f for f in all_inputs if f not in valid_inputs]\n",
    "\n",
    "if config[\"train_frac\"] > 1:\n",
    "    train_indices = list(range(0, len(train_inputs), config[\"train_frac\"]))\n",
    "    train_inputs = [train_inputs[i] for i in train_indices]\n",
    "\n",
    "print(\"Number of train files:\", len(train_inputs))\n",
    "print(\"Number of valid files:\", len(valid_inputs))\n",
    "\n",
    "train_outputs = inputs_files_to_output_files(train_inputs)\n",
    "valid_outputs = inputs_files_to_output_files(valid_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for denoising\n",
    "denoise_params = {\n",
    "    \"lowcut\": 0.002,\n",
    "    \"highcut\": 0.3,\n",
    "    \"fs\": 1.2,\n",
    "    \"order\": 4\n",
    "}\n",
    "\n",
    "# Create directory for saving denoised data\n",
    "save_dir = config.get(\"denoised_save_dir\", \"denoised_data\")\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save denoised training data\n",
    "#print(\"\\nPreprocessing and saving denoised training data...\")\n",
    "#denoised_train_inputs, denoised_train_outputs = denoise_and_save_dataset(\n",
    "#    train_inputs, \n",
    "#    train_outputs, \n",
    "#    save_dir=save_dir,\n",
    "#    prefix=\"train\", \n",
    "#    **denoise_params\n",
    "#)\n",
    "\n",
    "# Process and save denoised validation data\n",
    "#print(\"\\nPreprocessing and saving denoised validation data...\")\n",
    "#denoised_valid_inputs, denoised_valid_outputs = denoise_and_save_dataset(\n",
    "#    valid_inputs, \n",
    "#    valid_outputs, \n",
    "#    save_dir=save_dir,\n",
    "#    prefix=\"valid\", \n",
    "#    **denoise_params\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-14T18:20:26.578Z",
     "iopub.execute_input": "2025-05-14T16:28:53.018309Z",
     "iopub.status.busy": "2025-05-14T16:28:53.017978Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01  Step 1000/7031  Trn Loss: 311.46  LR: 5.00e-04  GPU Usage: 3.17GB  Elapsed Time: 0:02:22\n",
      "Epoch: 01  Step 2000/7031  Trn Loss: 278.77  LR: 5.00e-04  GPU Usage: 3.17GB  Elapsed Time: 0:04:37\n",
      "Epoch: 01  Step 3000/7031  Trn Loss: 260.65  LR: 5.00e-04  GPU Usage: 3.17GB  Elapsed Time: 0:06:54\n",
      "Epoch: 01  Step 4000/7031  Trn Loss: 246.58  LR: 5.00e-04  GPU Usage: 3.17GB  Elapsed Time: 0:09:10\n",
      "Epoch: 01  Step 5000/7031  Trn Loss: 235.72  LR: 5.00e-04  GPU Usage: 3.17GB  Elapsed Time: 0:11:27\n",
      "Epoch: 01  Step 6000/7031  Trn Loss: 226.86  LR: 5.00e-04  GPU Usage: 3.17GB  Elapsed Time: 0:13:43\n",
      "Epoch: 01  Step 7000/7031  Trn Loss: 219.45  LR: 5.00e-04  GPU Usage: 3.17GB  Elapsed Time: 0:15:59\n",
      "Epoch: 01  Step 7031/7031  Trn Loss: 219.26  LR: 5.00e-04  GPU Usage: 3.17GB  Elapsed Time: 0:16:03\n",
      "\n",
      "Epoch: 01  Trn Loss: 219.26  Val Loss: 179.76  GPU Usage: 5.21GB  Elapsed Time: 0:17:17\n",
      "\n",
      "New best val_loss: 179.76\n",
      "\n",
      "Epoch: 02  Step 1000/7031  Trn Loss: 165.83  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:19:31\n",
      "Epoch: 02  Step 2000/7031  Trn Loss: 163.24  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:21:44\n",
      "Epoch: 02  Step 3000/7031  Trn Loss: 160.83  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:23:57\n",
      "Epoch: 02  Step 4000/7031  Trn Loss: 158.54  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:26:11\n",
      "Epoch: 02  Step 5000/7031  Trn Loss: 156.44  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:28:27\n",
      "Epoch: 02  Step 6000/7031  Trn Loss: 154.56  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:30:44\n",
      "Epoch: 02  Step 7000/7031  Trn Loss: 152.59  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:32:59\n",
      "Epoch: 02  Step 7031/7031  Trn Loss: 152.55  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:33:03\n",
      "\n",
      "Epoch: 02  Trn Loss: 152.55  Val Loss: 144.60  GPU Usage: 5.21GB  Elapsed Time: 0:34:16\n",
      "\n",
      "New best val_loss: 144.60\n",
      "\n",
      "Epoch: 03  Step 1000/7031  Trn Loss: 137.17  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:36:33\n",
      "Epoch: 03  Step 2000/7031  Trn Loss: 136.35  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:38:54\n",
      "Epoch: 03  Step 3000/7031  Trn Loss: 135.13  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:41:15\n",
      "Epoch: 03  Step 4000/7031  Trn Loss: 134.30  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:43:36\n",
      "Epoch: 03  Step 5000/7031  Trn Loss: 133.34  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:45:50\n",
      "Epoch: 03  Step 6000/7031  Trn Loss: 132.47  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:48:04\n",
      "Epoch: 03  Step 7000/7031  Trn Loss: 131.70  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:50:17\n",
      "Epoch: 03  Step 7031/7031  Trn Loss: 131.67  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:50:21\n",
      "\n",
      "Epoch: 03  Trn Loss: 131.67  Val Loss: 126.20  GPU Usage: 5.21GB  Elapsed Time: 0:51:33\n",
      "\n",
      "New best val_loss: 126.20\n",
      "\n",
      "Epoch: 04  Step 1000/7031  Trn Loss: 123.20  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:53:52\n",
      "Epoch: 04  Step 2000/7031  Trn Loss: 122.58  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:56:11\n",
      "Epoch: 04  Step 3000/7031  Trn Loss: 122.05  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 0:58:30\n",
      "Epoch: 04  Step 4000/7031  Trn Loss: 121.46  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:00:50\n",
      "Epoch: 04  Step 5000/7031  Trn Loss: 120.86  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:03:09\n",
      "Epoch: 04  Step 6000/7031  Trn Loss: 120.30  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:05:26\n",
      "Epoch: 04  Step 7000/7031  Trn Loss: 119.74  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:07:40\n",
      "Epoch: 04  Step 7031/7031  Trn Loss: 119.73  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:07:44\n",
      "\n",
      "Epoch: 04  Trn Loss: 119.73  Val Loss: 158.80  GPU Usage: 5.21GB  Elapsed Time: 1:08:53\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 05  Step 1000/7031  Trn Loss: 113.10  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:11:07\n",
      "Epoch: 05  Step 2000/7031  Trn Loss: 113.04  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:13:21\n",
      "Epoch: 05  Step 3000/7031  Trn Loss: 112.58  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:15:35\n",
      "Epoch: 05  Step 4000/7031  Trn Loss: 112.24  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:17:49\n",
      "Epoch: 05  Step 5000/7031  Trn Loss: 112.04  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:20:02\n",
      "Epoch: 05  Step 6000/7031  Trn Loss: 111.76  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:22:13\n",
      "Epoch: 05  Step 7000/7031  Trn Loss: 111.45  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:24:25\n",
      "Epoch: 05  Step 7031/7031  Trn Loss: 111.43  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:24:29\n",
      "\n",
      "Epoch: 05  Trn Loss: 111.43  Val Loss: 119.67  GPU Usage: 5.21GB  Elapsed Time: 1:25:38\n",
      "\n",
      "New best val_loss: 119.67\n",
      "\n",
      "Epoch: 06  Step 1000/7031  Trn Loss: 107.14  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:27:50\n",
      "Epoch: 06  Step 2000/7031  Trn Loss: 106.52  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:30:03\n",
      "Epoch: 06  Step 3000/7031  Trn Loss: 106.70  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:32:15\n",
      "Epoch: 06  Step 4000/7031  Trn Loss: 106.33  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:34:27\n",
      "Epoch: 06  Step 5000/7031  Trn Loss: 105.99  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:36:39\n",
      "Epoch: 06  Step 6000/7031  Trn Loss: 105.66  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:38:52\n",
      "Epoch: 06  Step 7000/7031  Trn Loss: 105.41  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:41:06\n",
      "Epoch: 06  Step 7031/7031  Trn Loss: 105.42  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:41:10\n",
      "\n",
      "Epoch: 06  Trn Loss: 105.42  Val Loss: 109.62  GPU Usage: 5.21GB  Elapsed Time: 1:42:19\n",
      "\n",
      "New best val_loss: 109.62\n",
      "\n",
      "Epoch: 07  Step 1000/7031  Trn Loss: 101.62  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:44:32\n",
      "Epoch: 07  Step 2000/7031  Trn Loss: 101.30  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:46:46\n",
      "Epoch: 07  Step 3000/7031  Trn Loss: 101.43  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:48:59\n",
      "Epoch: 07  Step 4000/7031  Trn Loss: 101.27  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:51:12\n",
      "Epoch: 07  Step 5000/7031  Trn Loss: 101.10  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:53:25\n",
      "Epoch: 07  Step 6000/7031  Trn Loss: 100.88  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:55:37\n",
      "Epoch: 07  Step 7000/7031  Trn Loss: 100.63  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:57:48\n",
      "Epoch: 07  Step 7031/7031  Trn Loss: 100.62  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 1:57:52\n",
      "\n",
      "Epoch: 07  Trn Loss: 100.62  Val Loss: 105.03  GPU Usage: 5.21GB  Elapsed Time: 1:59:01\n",
      "\n",
      "New best val_loss: 105.03\n",
      "\n",
      "Epoch: 08  Step 1000/7031  Trn Loss: 97.68  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:01:14\n",
      "Epoch: 08  Step 2000/7031  Trn Loss: 97.64  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:03:26\n",
      "Epoch: 08  Step 3000/7031  Trn Loss: 97.13  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:05:38\n",
      "Epoch: 08  Step 4000/7031  Trn Loss: 97.09  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:07:50\n",
      "Epoch: 08  Step 5000/7031  Trn Loss: 96.95  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:10:02\n",
      "Epoch: 08  Step 6000/7031  Trn Loss: 96.83  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:12:14\n",
      "Epoch: 08  Step 7000/7031  Trn Loss: 96.71  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:14:26\n",
      "Epoch: 08  Step 7031/7031  Trn Loss: 96.70  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:14:30\n",
      "\n",
      "Epoch: 08  Trn Loss: 96.70  Val Loss: 108.08  GPU Usage: 5.21GB  Elapsed Time: 2:15:39\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 09  Step 1000/7031  Trn Loss: 94.20  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:17:51\n",
      "Epoch: 09  Step 2000/7031  Trn Loss: 93.52  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:20:03\n",
      "Epoch: 09  Step 3000/7031  Trn Loss: 93.70  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:22:15\n",
      "Epoch: 09  Step 4000/7031  Trn Loss: 93.54  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:24:27\n",
      "Epoch: 09  Step 5000/7031  Trn Loss: 93.55  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:26:39\n",
      "Epoch: 09  Step 6000/7031  Trn Loss: 93.41  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:28:51\n",
      "Epoch: 09  Step 7000/7031  Trn Loss: 93.37  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:31:03\n",
      "Epoch: 09  Step 7031/7031  Trn Loss: 93.37  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:31:07\n",
      "\n",
      "Epoch: 09  Trn Loss: 93.37  Val Loss: 99.61  GPU Usage: 5.21GB  Elapsed Time: 2:32:15\n",
      "\n",
      "New best val_loss: 99.61\n",
      "\n",
      "Epoch: 10  Step 1000/7031  Trn Loss: 90.53  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:34:28\n",
      "Epoch: 10  Step 2000/7031  Trn Loss: 90.53  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:36:40\n",
      "Epoch: 10  Step 3000/7031  Trn Loss: 90.77  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:38:53\n",
      "Epoch: 10  Step 4000/7031  Trn Loss: 90.68  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:41:05\n",
      "Epoch: 10  Step 5000/7031  Trn Loss: 90.57  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:43:17\n",
      "Epoch: 10  Step 6000/7031  Trn Loss: 90.51  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:45:29\n",
      "Epoch: 10  Step 7000/7031  Trn Loss: 90.51  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:47:41\n",
      "Epoch: 10  Step 7031/7031  Trn Loss: 90.52  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:47:46\n",
      "\n",
      "Epoch: 10  Trn Loss: 90.52  Val Loss: 98.67  GPU Usage: 5.21GB  Elapsed Time: 2:48:54\n",
      "\n",
      "New best val_loss: 98.67\n",
      "\n",
      "Epoch: 11  Step 1000/7031  Trn Loss: 87.62  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:51:06\n",
      "Epoch: 11  Step 2000/7031  Trn Loss: 87.73  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:53:19\n",
      "Epoch: 11  Step 3000/7031  Trn Loss: 87.80  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:55:31\n",
      "Epoch: 11  Step 4000/7031  Trn Loss: 87.93  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:57:43\n",
      "Epoch: 11  Step 5000/7031  Trn Loss: 87.81  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 2:59:55\n",
      "Epoch: 11  Step 6000/7031  Trn Loss: 87.91  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 3:02:07\n",
      "Epoch: 11  Step 7000/7031  Trn Loss: 87.84  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 3:04:20\n",
      "Epoch: 11  Step 7031/7031  Trn Loss: 87.84  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 3:04:24\n",
      "\n",
      "Epoch: 11  Trn Loss: 87.84  Val Loss: 134.63  GPU Usage: 5.21GB  Elapsed Time: 3:05:32\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 12  Step 1000/7031  Trn Loss: 85.23  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 3:07:45\n",
      "Epoch: 12  Step 2000/7031  Trn Loss: 85.50  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 3:09:57\n",
      "Epoch: 12  Step 3000/7031  Trn Loss: 85.62  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 3:12:09\n",
      "Epoch: 12  Step 4000/7031  Trn Loss: 85.57  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 3:14:20\n",
      "Epoch: 12  Step 5000/7031  Trn Loss: 85.64  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 3:16:32\n",
      "Epoch: 12  Step 6000/7031  Trn Loss: 85.65  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 3:18:45\n",
      "Epoch: 12  Step 7000/7031  Trn Loss: 85.62  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 3:20:56\n",
      "Epoch: 12  Step 7031/7031  Trn Loss: 85.61  LR: 5.00e-04  GPU Usage: 5.21GB  Elapsed Time: 3:21:00\n",
      "\n",
      "Epoch: 12  Trn Loss: 85.61  Val Loss: 121.65  GPU Usage: 5.21GB  Elapsed Time: 3:22:08\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 13  Step 1000/7031  Trn Loss: 75.83  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:24:21\n",
      "Epoch: 13  Step 2000/7031  Trn Loss: 75.55  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:26:33\n",
      "Epoch: 13  Step 3000/7031  Trn Loss: 75.20  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:28:45\n",
      "Epoch: 13  Step 4000/7031  Trn Loss: 75.09  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:30:57\n",
      "Epoch: 13  Step 5000/7031  Trn Loss: 75.10  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:33:09\n",
      "Epoch: 13  Step 6000/7031  Trn Loss: 74.98  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:35:21\n",
      "Epoch: 13  Step 7000/7031  Trn Loss: 74.83  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:37:33\n",
      "Epoch: 13  Step 7031/7031  Trn Loss: 74.82  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:37:37\n",
      "\n",
      "Epoch: 13  Trn Loss: 74.82  Val Loss: 84.61  GPU Usage: 5.21GB  Elapsed Time: 3:38:45\n",
      "\n",
      "New best val_loss: 84.61\n",
      "\n",
      "Epoch: 14  Step 1000/7031  Trn Loss: 72.01  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:40:57\n",
      "Epoch: 14  Step 2000/7031  Trn Loss: 72.20  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:43:10\n",
      "Epoch: 14  Step 3000/7031  Trn Loss: 72.43  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:45:22\n",
      "Epoch: 14  Step 4000/7031  Trn Loss: 72.45  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:47:34\n",
      "Epoch: 14  Step 5000/7031  Trn Loss: 72.42  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:49:46\n",
      "Epoch: 14  Step 6000/7031  Trn Loss: 72.43  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:51:58\n",
      "Epoch: 14  Step 7000/7031  Trn Loss: 72.42  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:54:10\n",
      "Epoch: 14  Step 7031/7031  Trn Loss: 72.42  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:54:14\n",
      "\n",
      "Epoch: 14  Trn Loss: 72.42  Val Loss: 81.68  GPU Usage: 5.21GB  Elapsed Time: 3:55:22\n",
      "\n",
      "New best val_loss: 81.68\n",
      "\n",
      "Epoch: 15  Step 1000/7031  Trn Loss: 70.78  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:57:35\n",
      "Epoch: 15  Step 2000/7031  Trn Loss: 70.83  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 3:59:48\n",
      "Epoch: 15  Step 3000/7031  Trn Loss: 70.79  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:02:00\n",
      "Epoch: 15  Step 4000/7031  Trn Loss: 70.91  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:04:12\n",
      "Epoch: 15  Step 5000/7031  Trn Loss: 70.93  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:06:24\n",
      "Epoch: 15  Step 6000/7031  Trn Loss: 70.95  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:08:36\n",
      "Epoch: 15  Step 7000/7031  Trn Loss: 70.99  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:10:48\n",
      "Epoch: 15  Step 7031/7031  Trn Loss: 70.99  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:10:53\n",
      "\n",
      "Epoch: 15  Trn Loss: 70.99  Val Loss: 87.61  GPU Usage: 5.21GB  Elapsed Time: 4:12:01\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 16  Step 1000/7031  Trn Loss: 69.37  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:14:14\n",
      "Epoch: 16  Step 2000/7031  Trn Loss: 69.99  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:16:26\n",
      "Epoch: 16  Step 3000/7031  Trn Loss: 69.81  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:18:38\n",
      "Epoch: 16  Step 4000/7031  Trn Loss: 69.76  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:20:50\n",
      "Epoch: 16  Step 5000/7031  Trn Loss: 69.74  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:23:01\n",
      "Epoch: 16  Step 6000/7031  Trn Loss: 69.78  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:25:13\n",
      "Epoch: 16  Step 7000/7031  Trn Loss: 69.81  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:27:25\n",
      "Epoch: 16  Step 7031/7031  Trn Loss: 69.81  LR: 1.58e-04  GPU Usage: 5.21GB  Elapsed Time: 4:27:29\n",
      "\n",
      "Epoch: 16  Trn Loss: 69.81  Val Loss: 83.25  GPU Usage: 5.21GB  Elapsed Time: 4:28:38\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 17  Step 1000/7031  Trn Loss: 66.35  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:30:50\n",
      "Epoch: 17  Step 2000/7031  Trn Loss: 66.43  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:33:02\n",
      "Epoch: 17  Step 3000/7031  Trn Loss: 66.34  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:35:14\n",
      "Epoch: 17  Step 4000/7031  Trn Loss: 66.20  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:37:26\n",
      "Epoch: 17  Step 5000/7031  Trn Loss: 66.08  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:39:38\n",
      "Epoch: 17  Step 6000/7031  Trn Loss: 66.06  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:41:50\n",
      "Epoch: 17  Step 7000/7031  Trn Loss: 66.04  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:44:02\n",
      "Epoch: 17  Step 7031/7031  Trn Loss: 66.04  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:44:06\n",
      "\n",
      "Epoch: 17  Trn Loss: 66.04  Val Loss: 78.14  GPU Usage: 5.21GB  Elapsed Time: 4:45:15\n",
      "\n",
      "New best val_loss: 78.14\n",
      "\n",
      "Epoch: 18  Step 1000/7031  Trn Loss: 65.17  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:47:27\n",
      "Epoch: 18  Step 2000/7031  Trn Loss: 65.42  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:49:40\n",
      "Epoch: 18  Step 3000/7031  Trn Loss: 65.37  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:51:52\n",
      "Epoch: 18  Step 4000/7031  Trn Loss: 65.23  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:54:04\n",
      "Epoch: 18  Step 5000/7031  Trn Loss: 65.23  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:56:16\n",
      "Epoch: 18  Step 6000/7031  Trn Loss: 65.27  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 4:58:29\n",
      "Epoch: 18  Step 7000/7031  Trn Loss: 65.23  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 5:00:41\n",
      "Epoch: 18  Step 7031/7031  Trn Loss: 65.23  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 5:00:45\n",
      "\n",
      "Epoch: 18  Trn Loss: 65.23  Val Loss: 79.82  GPU Usage: 5.21GB  Elapsed Time: 5:01:53\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 19  Step 1000/7031  Trn Loss: 64.66  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 5:04:06\n",
      "Epoch: 19  Step 2000/7031  Trn Loss: 64.80  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 5:06:18\n",
      "Epoch: 19  Step 3000/7031  Trn Loss: 64.65  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 5:08:30\n",
      "Epoch: 19  Step 4000/7031  Trn Loss: 64.63  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 5:10:42\n",
      "Epoch: 19  Step 5000/7031  Trn Loss: 64.65  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 5:12:54\n",
      "Epoch: 19  Step 6000/7031  Trn Loss: 64.63  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 5:15:05\n",
      "Epoch: 19  Step 7000/7031  Trn Loss: 64.69  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 5:17:17\n",
      "Epoch: 19  Step 7031/7031  Trn Loss: 64.69  LR: 5.00e-05  GPU Usage: 5.21GB  Elapsed Time: 5:17:21\n",
      "\n",
      "Epoch: 19  Trn Loss: 64.69  Val Loss: 80.19  GPU Usage: 5.21GB  Elapsed Time: 5:18:29\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 20  Step 1000/7031  Trn Loss: 63.86  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:20:42\n",
      "Epoch: 20  Step 2000/7031  Trn Loss: 63.41  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:22:53\n",
      "Epoch: 20  Step 3000/7031  Trn Loss: 63.30  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:25:05\n",
      "Epoch: 20  Step 4000/7031  Trn Loss: 63.35  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:27:17\n",
      "Epoch: 20  Step 5000/7031  Trn Loss: 63.37  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:29:29\n",
      "Epoch: 20  Step 6000/7031  Trn Loss: 63.35  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:31:41\n",
      "Epoch: 20  Step 7000/7031  Trn Loss: 63.40  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:33:53\n",
      "Epoch: 20  Step 7031/7031  Trn Loss: 63.40  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:33:57\n",
      "\n",
      "Epoch: 20  Trn Loss: 63.40  Val Loss: 77.59  GPU Usage: 5.21GB  Elapsed Time: 5:35:06\n",
      "\n",
      "New best val_loss: 77.59\n",
      "\n",
      "Epoch: 21  Step 1000/7031  Trn Loss: 63.50  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:37:17\n",
      "Epoch: 21  Step 2000/7031  Trn Loss: 63.16  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:39:28\n",
      "Epoch: 21  Step 3000/7031  Trn Loss: 63.21  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:41:39\n",
      "Epoch: 21  Step 4000/7031  Trn Loss: 63.28  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:43:49\n",
      "Epoch: 21  Step 5000/7031  Trn Loss: 63.29  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:46:00\n",
      "Epoch: 21  Step 6000/7031  Trn Loss: 63.20  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:48:11\n",
      "Epoch: 21  Step 7000/7031  Trn Loss: 63.17  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:50:22\n",
      "Epoch: 21  Step 7031/7031  Trn Loss: 63.16  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:50:26\n",
      "\n",
      "Epoch: 21  Trn Loss: 63.16  Val Loss: 77.20  GPU Usage: 5.21GB  Elapsed Time: 5:51:35\n",
      "\n",
      "New best val_loss: 77.20\n",
      "\n",
      "Epoch: 22  Step 1000/7031  Trn Loss: 63.46  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:53:46\n",
      "Epoch: 22  Step 2000/7031  Trn Loss: 63.12  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:55:57\n",
      "Epoch: 22  Step 3000/7031  Trn Loss: 63.06  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 5:58:08\n",
      "Epoch: 22  Step 4000/7031  Trn Loss: 63.07  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:00:19\n",
      "Epoch: 22  Step 5000/7031  Trn Loss: 62.99  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:02:29\n",
      "Epoch: 22  Step 6000/7031  Trn Loss: 62.96  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:04:40\n",
      "Epoch: 22  Step 7000/7031  Trn Loss: 62.95  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:06:50\n",
      "Epoch: 22  Step 7031/7031  Trn Loss: 62.95  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:06:54\n",
      "\n",
      "Epoch: 22  Trn Loss: 62.95  Val Loss: 77.04  GPU Usage: 5.21GB  Elapsed Time: 6:08:02\n",
      "\n",
      "New best val_loss: 77.04\n",
      "\n",
      "Epoch: 23  Step 1000/7031  Trn Loss: 62.72  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:10:13\n",
      "Epoch: 23  Step 2000/7031  Trn Loss: 62.66  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:12:24\n",
      "Epoch: 23  Step 3000/7031  Trn Loss: 62.71  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:14:35\n",
      "Epoch: 23  Step 4000/7031  Trn Loss: 62.72  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:16:46\n",
      "Epoch: 23  Step 5000/7031  Trn Loss: 62.83  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:18:56\n",
      "Epoch: 23  Step 6000/7031  Trn Loss: 62.82  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:21:07\n",
      "Epoch: 23  Step 7000/7031  Trn Loss: 62.77  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:23:18\n",
      "Epoch: 23  Step 7031/7031  Trn Loss: 62.78  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:23:22\n",
      "\n",
      "Epoch: 23  Trn Loss: 62.78  Val Loss: 77.14  GPU Usage: 5.21GB  Elapsed Time: 6:24:30\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 24  Step 1000/7031  Trn Loss: 62.38  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:26:41\n",
      "Epoch: 24  Step 2000/7031  Trn Loss: 62.41  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:28:51\n",
      "Epoch: 24  Step 3000/7031  Trn Loss: 62.53  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:31:01\n",
      "Epoch: 24  Step 4000/7031  Trn Loss: 62.42  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:33:12\n",
      "Epoch: 24  Step 5000/7031  Trn Loss: 62.51  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:35:22\n",
      "Epoch: 24  Step 6000/7031  Trn Loss: 62.58  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:37:33\n",
      "Epoch: 24  Step 7000/7031  Trn Loss: 62.61  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:39:43\n",
      "Epoch: 24  Step 7031/7031  Trn Loss: 62.61  LR: 1.58e-05  GPU Usage: 5.21GB  Elapsed Time: 6:39:47\n",
      "\n",
      "Epoch: 24  Trn Loss: 62.61  Val Loss: 77.09  GPU Usage: 5.21GB  Elapsed Time: 6:40:55\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 25  Step 1000/7031  Trn Loss: 62.33  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 6:43:05\n",
      "Epoch: 25  Step 2000/7031  Trn Loss: 62.37  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 6:45:16\n",
      "Epoch: 25  Step 3000/7031  Trn Loss: 62.33  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 6:47:26\n",
      "Epoch: 25  Step 4000/7031  Trn Loss: 62.39  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 6:49:37\n",
      "Epoch: 25  Step 5000/7031  Trn Loss: 62.29  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 6:51:47\n",
      "Epoch: 25  Step 6000/7031  Trn Loss: 62.22  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 6:53:57\n",
      "Epoch: 25  Step 7000/7031  Trn Loss: 62.18  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 6:56:07\n",
      "Epoch: 25  Step 7031/7031  Trn Loss: 62.19  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 6:56:11\n",
      "\n",
      "Epoch: 25  Trn Loss: 62.19  Val Loss: 76.82  GPU Usage: 5.21GB  Elapsed Time: 6:57:19\n",
      "\n",
      "New best val_loss: 76.82\n",
      "\n",
      "Epoch: 26  Step 1000/7031  Trn Loss: 61.51  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 6:59:30\n",
      "Epoch: 26  Step 2000/7031  Trn Loss: 62.08  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:01:41\n",
      "Epoch: 26  Step 3000/7031  Trn Loss: 62.10  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:03:52\n",
      "Epoch: 26  Step 4000/7031  Trn Loss: 62.11  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:06:03\n",
      "Epoch: 26  Step 5000/7031  Trn Loss: 62.16  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:08:13\n",
      "Epoch: 26  Step 6000/7031  Trn Loss: 62.13  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:10:24\n",
      "Epoch: 26  Step 7000/7031  Trn Loss: 62.11  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:12:35\n",
      "Epoch: 26  Step 7031/7031  Trn Loss: 62.11  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:12:39\n",
      "\n",
      "Epoch: 26  Trn Loss: 62.11  Val Loss: 77.13  GPU Usage: 5.21GB  Elapsed Time: 7:13:47\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 27  Step 1000/7031  Trn Loss: 62.22  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:15:57\n",
      "Epoch: 27  Step 2000/7031  Trn Loss: 62.00  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:18:07\n",
      "Epoch: 27  Step 3000/7031  Trn Loss: 61.97  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:20:18\n",
      "Epoch: 27  Step 4000/7031  Trn Loss: 62.08  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:22:29\n",
      "Epoch: 27  Step 5000/7031  Trn Loss: 62.03  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:24:39\n",
      "Epoch: 27  Step 6000/7031  Trn Loss: 62.05  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:26:49\n",
      "Epoch: 27  Step 7000/7031  Trn Loss: 62.05  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:29:00\n",
      "Epoch: 27  Step 7031/7031  Trn Loss: 62.05  LR: 5.00e-06  GPU Usage: 5.21GB  Elapsed Time: 7:29:04\n",
      "\n",
      "Epoch: 27  Trn Loss: 62.05  Val Loss: 77.35  GPU Usage: 5.21GB  Elapsed Time: 7:30:12\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 28  Step 1000/7031  Trn Loss: 61.81  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:32:23\n",
      "Epoch: 28  Step 2000/7031  Trn Loss: 61.83  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:34:33\n",
      "Epoch: 28  Step 3000/7031  Trn Loss: 61.78  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:36:44\n",
      "Epoch: 28  Step 4000/7031  Trn Loss: 61.82  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:38:54\n",
      "Epoch: 28  Step 5000/7031  Trn Loss: 61.86  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:41:05\n",
      "Epoch: 28  Step 6000/7031  Trn Loss: 61.88  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:43:15\n",
      "Epoch: 28  Step 7000/7031  Trn Loss: 61.88  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:45:25\n",
      "Epoch: 28  Step 7031/7031  Trn Loss: 61.89  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:45:30\n",
      "\n",
      "Epoch: 28  Trn Loss: 61.89  Val Loss: 77.05  GPU Usage: 5.21GB  Elapsed Time: 7:46:38\n",
      "\n",
      "Epochs without improvement: 3\n",
      "\n",
      "Epoch: 29  Step 1000/7031  Trn Loss: 61.70  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:48:48\n",
      "Epoch: 29  Step 2000/7031  Trn Loss: 61.65  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:50:59\n",
      "Epoch: 29  Step 3000/7031  Trn Loss: 61.62  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:53:10\n",
      "Epoch: 29  Step 4000/7031  Trn Loss: 61.71  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:55:20\n",
      "Epoch: 29  Step 5000/7031  Trn Loss: 61.85  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:57:30\n",
      "Epoch: 29  Step 6000/7031  Trn Loss: 61.91  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 7:59:40\n",
      "Epoch: 29  Step 7000/7031  Trn Loss: 61.89  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 8:01:51\n",
      "Epoch: 29  Step 7031/7031  Trn Loss: 61.88  LR: 1.58e-06  GPU Usage: 5.21GB  Elapsed Time: 8:01:55\n",
      "\n",
      "Epoch: 29  Trn Loss: 61.88  Val Loss: 76.93  GPU Usage: 5.21GB  Elapsed Time: 8:03:03\n",
      "\n",
      "Epochs without improvement: 4\n",
      "\n",
      "\n",
      "==================================================\n",
      "MODEL TRAINING COMPLETE\n",
      "==================================================\n",
      "\n",
      "Model Summary:\n",
      "Architecture: UNet\n",
      "Total parameters: 52,079,841\n",
      "Trainable parameters: 52,079,841\n",
      "Best validation loss: 76.8202\n",
      "Total training time: 8:03:03\n",
      "\n",
      "Model Structure:\n",
      "UNet(\n",
      "  (initial_pool): AvgPool2d(kernel_size=(14, 1), stride=(14, 1), padding=0)\n",
      "  (encoder_convs): ModuleList(\n",
      "    (0): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder_pools): ModuleList(\n",
      "    (0-4): 5 x MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (inc): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Identity()\n",
      "  )\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "\n",
      "Model summary saved to model_summary_76.8202.txt\n"
     ]
    }
   ],
   "source": [
    "# Create datasets using pre-denoised data\n",
    "#dstrain = PreDenoisedSeismicDataset(\n",
    "#    denoised_train_inputs, \n",
    "#    denoised_train_outputs,\n",
    "#    n_examples_per_file=config.get(\"n_examples_per_file\", 500)\n",
    "#)\n",
    "\n",
    "#dsvalid = PreDenoisedSeismicDataset(\n",
    "#    denoised_valid_inputs, \n",
    "#    denoised_valid_outputs,\n",
    "#    n_examples_per_file=config.get(\"n_examples_per_file\", 500)\n",
    "#)\n",
    "\n",
    "# Load seismic\n",
    "dstrain = SeismicDataset(train_inputs, train_outputs)\n",
    "dsvalid = SeismicDataset(valid_inputs, valid_outputs)\n",
    "\n",
    "# Create data loaders\n",
    "dltrain = DataLoader(\n",
    "    dstrain,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,  # Can shuffle now that we're not processing on-the-fly\n",
    "    pin_memory=config.get(\"pin_memory\", False),\n",
    "    drop_last=True,\n",
    "    num_workers=config.get(\"num_workers\", 0),\n",
    "    persistent_workers=config.get(\"persistent_workers\", False),\n",
    ")\n",
    "\n",
    "dlvalid = DataLoader(\n",
    "    dsvalid,\n",
    "    batch_size=4*config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    pin_memory=config.get(\"pin_memory\", False),\n",
    "    drop_last=False,\n",
    "    num_workers=config.get(\"num_workers\", 0),\n",
    "    persistent_workers=config.get(\"persistent_workers\", False),\n",
    ")\n",
    "\n",
    "# Set up device, model, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(**config[\"model\"][\"unet_params\"]).to(device)\n",
    "\n",
    "if config[\"read_weights\"] is not None:\n",
    "    print(\"Reading weights from:\", config[\"read_weights\"])\n",
    "    model.load_state_dict(torch.load(config[\"read_weights\"], weights_only=True))\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), **config[\"optimizer\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', **config[\"scheduler\"][\"params\"])\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = 10000.0\n",
    "epochs_wo_improvement = 0\n",
    "t0 = time.time()\n",
    "\n",
    "for epoch in range(1, config[\"max_epochs\"] + 1):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for step, (inputs, targets) in enumerate(dltrain):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        if step % config[\"print_freq\"] == config[\"print_freq\"] - 1 or step == len(dltrain) - 1:\n",
    "            trn_loss = np.mean(train_losses)\n",
    "            t1 = format_time(time.time() - t0)\n",
    "            free, total = torch.cuda.mem_get_info(device=0)\n",
    "            mem_used = (total - free) / 1024**3\n",
    "            lr = optimizer.param_groups[-1]['lr']\n",
    "            print(\n",
    "                f\"Epoch: {epoch:02d}  Step {step+1}/{len(dltrain)}  Trn Loss: {trn_loss:.2f}  LR: {lr:.2e}  GPU Usage: {mem_used:.2f}GB  Elapsed Time: {t1}\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    valid_losses = []\n",
    "    \n",
    "    for inputs, targets in dlvalid:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        valid_losses.append(loss.item())\n",
    "\n",
    "    t1 = format_time(time.time() - t0)\n",
    "    trn_loss = np.mean(train_losses)\n",
    "    val_loss = np.mean(valid_losses)\n",
    "\n",
    "    free, total = torch.cuda.mem_get_info(device=0)\n",
    "    mem_used = (total - free) / 1024**3\n",
    "\n",
    "    print(\n",
    "        f\"\\nEpoch: {epoch:02d}  Trn Loss: {trn_loss:.2f}  Val Loss: {val_loss:.2f}  GPU Usage: {mem_used:.2f}GB  Elapsed Time: {t1}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_wo_improvement = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"\\nNew best val_loss: {val_loss:.2f}\\n\", flush=True)\n",
    "    else:\n",
    "        epochs_wo_improvement += 1\n",
    "        print(f\"\\nEpochs without improvement: {epochs_wo_improvement}\\n\", flush=True)\n",
    "\n",
    "    if epochs_wo_improvement == config[\"es_epochs\"]:\n",
    "        break\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"Architecture: UNet\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Total training time: {format_time(time.time() - t0)}\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\nModel Structure:\")\n",
    "print(model)\n",
    "print(\"=\"*50)\n",
    "\n",
    "torch.save(model.state_dict(), f\"{best_val_loss:.4f}_model.pth\")\n",
    "\n",
    "# Create a summary text file\n",
    "summary_filename = f\"model_summary_{best_val_loss:.4f}.txt\"\n",
    "\n",
    "with open(summary_filename, 'w') as f:\n",
    "    # Write header\n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "    f.write(\"MODEL TRAINING SUMMARY\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    \n",
    "    # Write model information\n",
    "    f.write(\"MODEL INFORMATION\\n\")\n",
    "    f.write(f\"Architecture: UNet\\n\")\n",
    "    f.write(f\"Total parameters: {total_params:,}\\n\")\n",
    "    f.write(f\"Trainable parameters: {trainable_params:,}\\n\")\n",
    "    f.write(f\"Best validation loss: {best_val_loss:.4f}\\n\")\n",
    "    f.write(f\"Total training time: {format_time(time.time() - t0)}\\n\\n\")\n",
    "    \n",
    "    # Write configuration information\n",
    "    f.write(\"MODEL CONFIGURATION\\n\")\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, dict):\n",
    "            f.write(f\"{key}:\\n\")\n",
    "            for sub_key, sub_value in value.items():\n",
    "                f.write(f\"  {sub_key}: {sub_value}\\n\")\n",
    "        else:\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    # Write model structure\n",
    "    f.write(\"MODEL STRUCTURE\\n\")\n",
    "    f.write(str(model) + \"\\n\")\n",
    "    \n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "\n",
    "print(f\"\\nModel summary saved to {summary_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n",
      "Architecture: UNet\n",
      "Total parameters: 52,079,841\n",
      "Trainable parameters: 52,079,841\n",
      "Best validation loss: 76.8202\n",
      "Total training time: 8:03:03\n",
      "\n",
      "Model Structure:\n",
      "UNet(\n",
      "  (initial_pool): AvgPool2d(kernel_size=(14, 1), stride=(14, 1), padding=0)\n",
      "  (encoder_convs): ModuleList(\n",
      "    (0): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder_pools): ModuleList(\n",
      "    (0-4): 5 x MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (inc): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Identity()\n",
      "  )\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"Architecture: UNet\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Total training time: {format_time(time.time() - t0)}\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\nModel Structure:\")\n",
    "print(model)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-14T16:28:07.669373Z",
     "iopub.status.idle": "2025-05-14T16:28:07.669589Z",
     "shell.execute_reply": "2025-05-14T16:28:07.669495Z",
     "shell.execute_reply.started": "2025-05-14T16:28:07.669486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Inference ===============\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== Inference ===============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-14T16:28:07.670246Z",
     "iopub.status.idle": "2025-05-14T16:28:07.670565Z",
     "shell.execute_reply": "2025-05-14T16:28:07.670421Z",
     "shell.execute_reply.started": "2025-05-14T16:28:07.670405Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0:06:04\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "t0 = time.time()\n",
    "\n",
    "test_files = list(Path(\"input/openfwi_float16_test/test\").glob(\"*.npy\"))\n",
    "x_cols = [f\"x_{i}\" for i in range(1, 70, 2)]\n",
    "fieldnames = [\"oid_ypos\"] + x_cols\n",
    "ds = TestDataset(test_files)\n",
    "dl = DataLoader(ds, batch_size=4*config[\"batch_size\"], num_workers=0, pin_memory=False)\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "\n",
    "model.eval()\n",
    "with open(\"submission.csv\", \"wt\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for inputs, oids_test in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        with torch.inference_mode():\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        y_preds = outputs[:, 0].cpu().numpy()\n",
    "\n",
    "        for y_pred, oid_test in zip(y_preds, oids_test):\n",
    "            for y_pos in range(70):\n",
    "                row = dict(zip(x_cols, [y_pred[y_pos, x_pos] for x_pos in range(1, 70, 2)]))\n",
    "                row[\"oid_ypos\"] = f\"{oid_test}_y_{y_pos}\"\n",
    "\n",
    "                writer.writerow(row)\n",
    "\n",
    "t1 = format_time(time.time() - t0)\n",
    "print(f\"Inference Time: {t1}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11756775,
     "sourceId": 39763,
     "sourceType": "competition"
    },
    {
     "datasetId": 7253205,
     "sourceId": 11568812,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7253605,
     "sourceId": 11569667,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7253661,
     "sourceId": 11569755,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
