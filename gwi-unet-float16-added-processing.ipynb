{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T14:53:18.823481Z",
     "iopub.status.busy": "2025-04-25T14:53:18.823205Z",
     "iopub.status.idle": "2025-04-25T14:53:23.506381Z",
     "shell.execute_reply": "2025-04-25T14:53:23.505626Z",
     "shell.execute_reply.started": "2025-04-25T14:53:18.823463Z"
    }
   },
   "source": [
    "# Improved UNet pipepline with larger dataset - Copied Notebook with Modifications\n",
    "\n",
    "#### [<u>Initial version</u>](https://www.kaggle.com/code/egortrushin/gwi-improved-unet-pipepline-with-larger-dataset)\n",
    "\n",
    "- We used UNet model as introduced in [<u>5 depth U net with residual</u>](https://www.kaggle.com/code/adhok93/5-depth-u-net-with-residual) Notebook.\n",
    "- We used part of Full OpenWFI dataset, which was introduced in [<u>OpenFWI InversionNet Train with 670G Datasets</u>](https://www.kaggle.com/code/seshurajup/openfwi-inversionnet-train-with-670g-datasets) Notebook.\n",
    "\n",
    "#### <u>Copied version</u>\n",
    "\n",
    "- We will use openFWI dataset converted from float32 to float16 ([<u>openfwi_float16_1</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-1), [<u>openfwi_float16_2</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-2), and [<u>openfwi_float16_test</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-test)). Since reading of data from disk is a bottleneck here, the conversion allows us to read data from disk twice faster and to use twice more data in training for the same runtime.\n",
    "\n",
    "#### <u>Added Processing version</u>\n",
    "\n",
    "- I have added denoising and normalization to see if "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:02.356186Z",
     "iopub.status.busy": "2025-05-14T16:28:02.355913Z",
     "iopub.status.idle": "2025-05-14T16:28:02.366251Z",
     "shell.execute_reply": "2025-05-14T16:28:02.365259Z",
     "shell.execute_reply.started": "2025-05-14T16:28:02.356159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "data_path: /input\n",
    "model: \n",
    "    name: UNet\n",
    "    unet_params:\n",
    "        init_features: 32\n",
    "        depth: 5\n",
    "read_weights: null\n",
    "batch_size: 64\n",
    "print_freq: 1000\n",
    "max_epochs: 20\n",
    "es_epochs: 4\n",
    "seed: 42\n",
    "valid_frac: 16\n",
    "train_frac: 1\n",
    "optimizer:\n",
    "    lr: 0.0005\n",
    "    weight_decay: 0.001\n",
    "scheduler:\n",
    "    params:\n",
    "        factor: 0.316227766\n",
    "        patience: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, filtfilt, sosfilt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_sharing_strategy('file_system')\n",
    "\n",
    "# Utilities\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:02.367961Z",
     "iopub.status.busy": "2025-05-14T16:28:02.367746Z",
     "iopub.status.idle": "2025-05-14T16:28:06.750047Z",
     "shell.execute_reply": "2025-05-14T16:28:06.749262Z",
     "shell.execute_reply.started": "2025-05-14T16:28:02.367942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "def inputs_files_to_output_files(input_files):\n",
    "    return [\n",
    "        Path(str(f).replace('seis', 'vel').replace('data', 'model'))\n",
    "        for f in input_files\n",
    "    ]\n",
    "\n",
    "def get_train_files(data_path):\n",
    "\n",
    "    all_inputs = [\n",
    "        f\n",
    "        for f in\n",
    "        Path(data_path).rglob('*.npy')\n",
    "        if ('seis' in f.stem) or ('data' in f.stem)\n",
    "    ]\n",
    "\n",
    "    all_outputs = inputs_files_to_output_files(all_inputs)\n",
    "\n",
    "    assert all(f.exists() for f in all_outputs)\n",
    "\n",
    "    return all_inputs, all_outputs\n",
    "\n",
    "class SeismicDataset(Dataset):\n",
    "    def __init__(self, inputs_files, output_files, n_examples_per_file=500):\n",
    "        assert len(inputs_files) == len(output_files)\n",
    "        self.inputs_files = inputs_files\n",
    "        self.output_files = output_files\n",
    "        self.n_examples_per_file = n_examples_per_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_files) * self.n_examples_per_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate file offset and sample offset within file\n",
    "        file_idx = idx // self.n_examples_per_file\n",
    "        sample_idx = idx % self.n_examples_per_file\n",
    "\n",
    "        X = np.load(self.inputs_files[file_idx], mmap_mode='r')\n",
    "        y = np.load(self.output_files[file_idx], mmap_mode='r')\n",
    "\n",
    "        try:\n",
    "            return X[sample_idx].copy(), y[sample_idx].copy()\n",
    "        finally:\n",
    "            del X, y\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_files):\n",
    "        self.test_files = test_files\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        test_file = self.test_files[i]\n",
    "\n",
    "        return np.load(test_file), test_file.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:06.751541Z",
     "iopub.status.busy": "2025-05-14T16:28:06.751295Z",
     "iopub.status.idle": "2025-05-14T16:28:06.773854Z",
     "shell.execute_reply": "2025-05-14T16:28:06.773264Z",
     "shell.execute_reply.started": "2025-05-14T16:28:06.751525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class ResidualDoubleConv(nn.Module):\n",
    "    \"\"\"(Convolution => [BN] => ReLU) * 2 + Residual Connection\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "\n",
    "        # First convolution layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Second convolution layer\n",
    "        self.conv2 = nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Shortcut connection to handle potential channel mismatch\n",
    "        if in_channels == out_channels:\n",
    "            self.shortcut = nn.Identity()\n",
    "        else:\n",
    "            # Projection shortcut: 1x1 conv + BN to match output channels\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # Store the input for the residual connection\n",
    "\n",
    "        # First conv block\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # Second conv block (without final ReLU yet)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Apply shortcut to the identity path\n",
    "        identity_mapped = self.shortcut(identity)\n",
    "\n",
    "        # Add the residual connection\n",
    "        out += identity_mapped\n",
    "\n",
    "        # Apply final ReLU\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then ResidualDoubleConv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "            # Input to ResidualDoubleConv = channels from upsampled layer below + channels from skip connection\n",
    "            # Output of ResidualDoubleConv = desired output channels for this decoder stage\n",
    "            self.conv = ResidualDoubleConv(in_channels + out_channels, out_channels) # Use ResidualDoubleConv\n",
    "\n",
    "        else: # Using ConvTranspose2d\n",
    "            # ConvTranspose halves the channels: in_channels -> in_channels // 2\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            # Input channels to ResidualDoubleConv\n",
    "            conv_in_channels = in_channels // 2 # Channels after ConvTranspose\n",
    "            skip_channels = out_channels       # Channels from skip connection\n",
    "            total_in_channels = conv_in_channels + skip_channels\n",
    "            self.conv = ResidualDoubleConv(total_in_channels, out_channels) # Use ResidualDoubleConv\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # x1 is the feature map from the layer below (needs upsampling)\n",
    "        # x2 is the skip connection from the corresponding encoder layer\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        # Pad x1 if its dimensions don't match x2 after upsampling\n",
    "        # Input is CHW\n",
    "        diffY = x2.size(2) - x1.size(2)\n",
    "        diffX = x2.size(3) - x1.size(3)\n",
    "\n",
    "        # Pad format: (padding_left, padding_right, padding_top, padding_bottom)\n",
    "        x1 = F.pad(\n",
    "            x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2]\n",
    "        )\n",
    "\n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"1x1 Convolution for the output layer\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net architecture implementation with Residual Blocks\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_channels=5,\n",
    "        n_classes=1,\n",
    "        init_features=32,\n",
    "        depth=5, # number of pooling layers\n",
    "        bilinear=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.depth = depth\n",
    "\n",
    "        self.initial_pool = nn.AvgPool2d(kernel_size=(14, 1), stride=(14, 1))\n",
    "\n",
    "        # --- Encoder ---\n",
    "        self.encoder_convs = nn.ModuleList() # Store conv blocks\n",
    "        self.encoder_pools = nn.ModuleList() # Store pool layers\n",
    "\n",
    "        # Initial conv block (no pooling before it)\n",
    "        # Use ResidualDoubleConv for the initial convolution block\n",
    "        self.inc = ResidualDoubleConv(n_channels, init_features)\n",
    "        self.encoder_convs.append(self.inc)\n",
    "\n",
    "        current_features = init_features\n",
    "        for _ in range(depth):\n",
    "            # Define convolution block for this stage\n",
    "            conv = ResidualDoubleConv(current_features, current_features * 2)\n",
    "            # Define pooling layer for this stage\n",
    "            pool = nn.MaxPool2d(2)\n",
    "            self.encoder_convs.append(conv)\n",
    "            self.encoder_pools.append(pool)\n",
    "            current_features *= 2\n",
    "\n",
    "        # --- Bottleneck ---\n",
    "        # Use ResidualDoubleConv for the bottleneck\n",
    "        self.bottleneck = ResidualDoubleConv(current_features, current_features)\n",
    "\n",
    "        # --- Decoder ---\n",
    "        self.decoder_blocks = nn.ModuleList()\n",
    "        # Input features start from bottleneck output features\n",
    "        # Output features at each stage are halved\n",
    "        for _ in range(depth):\n",
    "            # Up block uses ResidualDoubleConv internally and handles channels\n",
    "            up_block = Up(current_features, current_features // 2, bilinear)\n",
    "            self.decoder_blocks.append(up_block)\n",
    "            current_features //= 2 # Halve features for next Up block input\n",
    "\n",
    "        # --- Output Layer ---\n",
    "        # Input features are the output features of the last Up block\n",
    "        self.outc = OutConv(current_features, n_classes)\n",
    "\n",
    "    def _pad_or_crop(self, x, target_h=70, target_w=70):\n",
    "        \"\"\"Pads or crops input tensor x to target height and width.\"\"\"\n",
    "        _, _, h, w = x.shape\n",
    "        # Pad Height if needed\n",
    "        if h < target_h:\n",
    "            pad_top = (target_h - h) // 2\n",
    "            pad_bottom = target_h - h - pad_top\n",
    "            x = F.pad(x, (0, 0, pad_top, pad_bottom))  # Pad height only\n",
    "            h = target_h\n",
    "        # Pad Width if needed\n",
    "        if w < target_w:\n",
    "            pad_left = (target_w - w) // 2\n",
    "            pad_right = target_w - w - pad_left\n",
    "            x = F.pad(x, (pad_left, pad_right, 0, 0))  # Pad width only\n",
    "            w = target_w\n",
    "        # Crop Height if needed\n",
    "        if h > target_h:\n",
    "            crop_top = (h - target_h) // 2\n",
    "            # Use slicing to crop\n",
    "            x = x[:, :, crop_top : crop_top + target_h, :]\n",
    "            h = target_h\n",
    "        # Crop Width if needed\n",
    "        if w > target_w:\n",
    "            crop_left = (w - target_w) // 2\n",
    "            x = x[:, :, :, crop_left : crop_left + target_w]\n",
    "            w = target_w\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial pooling and resizing\n",
    "        x_pooled = self.initial_pool(x)\n",
    "        x_resized = self._pad_or_crop(x_pooled, target_h=70, target_w=70)\n",
    "\n",
    "        # --- Encoder Path ---\n",
    "        skip_connections = []\n",
    "        xi = x_resized\n",
    "\n",
    "        # Apply initial conv (inc)\n",
    "        xi = self.encoder_convs[0](xi)\n",
    "        skip_connections.append(xi) # Store output of inc\n",
    "\n",
    "        # Apply subsequent encoder convs and pools\n",
    "        # self.depth is the number of pooling layers\n",
    "        for i in range(self.depth):\n",
    "            # Apply conv block for this stage\n",
    "            xi = self.encoder_convs[i+1](xi)\n",
    "            # Store skip connection *before* pooling\n",
    "            skip_connections.append(xi)\n",
    "            # Apply pooling layer for this stage\n",
    "            xi = self.encoder_pools[i](xi)\n",
    "\n",
    "        # Apply bottleneck conv\n",
    "        xi = self.bottleneck(xi)\n",
    "\n",
    "        # --- Decoder Path ---\n",
    "        xu = xi # Start with bottleneck output\n",
    "        # Iterate through decoder blocks and corresponding skip connections in reverse\n",
    "        for i, block in enumerate(self.decoder_blocks):\n",
    "            # Determine the correct skip connection index from the end\n",
    "            # Example: depth=5. Skips stored: [inc, enc1, enc2, enc3, enc4] (indices 0-4)\n",
    "            # Decoder 0 (Up(1024, 512)) needs skip 4 (enc4)\n",
    "            # Decoder 1 (Up(512, 256)) needs skip 3 (enc3) ...\n",
    "            # Decoder 4 (Up(64, 32)) needs skip 0 (inc)\n",
    "            skip_index = self.depth - 1 - i\n",
    "            skip = skip_connections[skip_index]\n",
    "            xu = block(xu, skip) # Up block combines xu (from below) and skip\n",
    "\n",
    "        # --- Final Output ---\n",
    "        logits = self.outc(xu)\n",
    "        # Apply scaling and offset specific to the problem's target range\n",
    "        output = logits * 1000.0 + 1500.0\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:06.775018Z",
     "iopub.status.busy": "2025-05-14T16:28:06.774813Z",
     "iopub.status.idle": "2025-05-14T16:28:06.800170Z",
     "shell.execute_reply": "2025-05-14T16:28:06.799440Z",
     "shell.execute_reply.started": "2025-05-14T16:28:06.775002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "def butter_bandpass(lowcut, highcut, fs, order=2):\n",
    "    \"\"\"Design a Butterworth bandpass filter.\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band', output='ba')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    \"\"\"Apply a Butterworth bandpass filter to a 1D signal.\"\"\"\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def denoise_seismic_with_bandpass(data, lowcut=0.01, highcut=0.3, fs=1.2, order=2):\n",
    "    \"\"\"\n",
    "    Apply Butterworth bandpass filter to seismic data.\n",
    "    Handles 2D, 3D, or 4D data.\n",
    "    Inner tqdm progress bars are disabled to reduce verbosity.\n",
    "    \"\"\"\n",
    "    original_shape = data.shape\n",
    "    \n",
    "    if len(original_shape) == 4: # 4D data (e.g., batch, channels, height, width)\n",
    "        denoised_data = np.zeros_like(data)\n",
    "        # Iterate through the first dimension (samples in batch)\n",
    "        for s_idx in tqdm(range(original_shape[0]), desc=\"Processing samples in batch\", leave=False, disable=True):\n",
    "            for c_idx in range(original_shape[1]): # Channels\n",
    "                denoised_data[s_idx, c_idx] = denoise_seismic_with_bandpass(\n",
    "                    data[s_idx, c_idx], lowcut, highcut, fs, order\n",
    "                )\n",
    "        return denoised_data\n",
    "    \n",
    "    elif len(original_shape) == 3: # 3D data (e.g., batch/channels, height, width)\n",
    "        denoised_data = np.zeros_like(data)\n",
    "        # Iterate through the first dimension (channels or slices)\n",
    "        for c_idx in tqdm(range(original_shape[0]), desc=\"Processing channels/slices\", leave=False, disable=True):\n",
    "            denoised_data[c_idx] = denoise_seismic_with_bandpass(\n",
    "                data[c_idx], lowcut, highcut, fs, order\n",
    "            )\n",
    "        return denoised_data\n",
    "    \n",
    "    elif len(original_shape) == 2: # 2D data (height, width) - filter per trace\n",
    "        denoised_data = np.zeros_like(data)\n",
    "        for i in range(data.shape[1]): # Iterate over traces (width)\n",
    "            trace = data[:, i]\n",
    "            # filtfilt requirement: signal length > 3 * filter order\n",
    "            if len(trace) > order * 3:\n",
    "                 denoised_data[:, i] = butter_bandpass_filter(trace, lowcut, highcut, fs, order)\n",
    "            else:\n",
    "                # To avoid verbose output, this warning is kept as a comment.\n",
    "                # print(f\"Warning: Trace length ({len(trace)}) for trace {i} too short for filter order ({order}). Copying original trace.\")\n",
    "                denoised_data[:, i] = trace\n",
    "        return denoised_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported data shape: {original_shape}. Expected 2D, 3D, or 4D.\")\n",
    "\n",
    "# Revised memory-efficient function with reduced print output\n",
    "def denoise_training_dataset_memory_efficient(train_loader, lowcut=0.01, highcut=0.3, fs=1.2, order=2):\n",
    "    denoised_inputs_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    print(\"Starting memory-efficient denoising process...\")\n",
    "    \n",
    "    try:\n",
    "        total_batches = len(train_loader)\n",
    "    except TypeError:\n",
    "        total_batches = None \n",
    "\n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    # This is the main progress bar the user will see, updating per batch\n",
    "    for inputs_batch, targets_batch in tqdm(train_loader, desc=\"Denoising batches\", total=total_batches, unit=\"batch\"):\n",
    "        inputs_batch_np = inputs_batch.numpy() \n",
    "        \n",
    "        denoised_batch = denoise_seismic_with_bandpass(\n",
    "            inputs_batch_np, lowcut=lowcut, highcut=highcut, fs=fs, order=order\n",
    "        )\n",
    "\n",
    "        denoised_inputs_list.append(denoised_batch)\n",
    "        targets_list.append(targets_batch.numpy()) \n",
    "    \n",
    "    overall_elapsed_time = time.time() - overall_start_time\n",
    "    # Adding a newline to ensure this print is on a new line after tqdm finishes\n",
    "    print(f\"\\nAll batches processed in {overall_elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    print(\"Concatenating denoised batches and targets...\")\n",
    "    concatenation_start_time = time.time()\n",
    "    \n",
    "    final_denoised_inputs = np.concatenate(denoised_inputs_list, axis=0)\n",
    "    final_targets = np.concatenate(targets_list, axis=0)\n",
    "    \n",
    "    concatenation_elapsed_time = time.time() - concatenation_start_time\n",
    "    print(f\"Concatenation completed in {concatenation_elapsed_time:.2f} seconds.\")\n",
    "    \n",
    "    return final_denoised_inputs, final_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a custom dataset that applies denoising on-the-fly\n",
    "class DenoisedSeismicDataset(Dataset):\n",
    "    def __init__(self, inputs_files, output_files, n_examples_per_file=250, \n",
    "                 apply_denoising=True, lowcut=0.01, highcut=0.3, fs=1.2, order=2):\n",
    "        assert len(inputs_files) == len(output_files)\n",
    "        self.inputs_files = inputs_files\n",
    "        self.output_files = output_files\n",
    "        self.n_examples_per_file = n_examples_per_file\n",
    "        self.apply_denoising = apply_denoising\n",
    "        self.lowcut = lowcut\n",
    "        self.highcut = highcut\n",
    "        self.fs = fs\n",
    "        self.order = order\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_files) * self.n_examples_per_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate file offset and sample offset within file\n",
    "        file_idx = idx // self.n_examples_per_file\n",
    "        sample_idx = idx % self.n_examples_per_file\n",
    "\n",
    "        X = np.load(self.inputs_files[file_idx], mmap_mode='r')\n",
    "        y = np.load(self.output_files[file_idx], mmap_mode='r')\n",
    "\n",
    "        try:\n",
    "            input_data = X[sample_idx].copy()\n",
    "            target_data = y[sample_idx].copy()\n",
    "            \n",
    "            # Apply denoising if enabled\n",
    "            if self.apply_denoising:\n",
    "                input_data = denoise_seismic_with_bandpass(\n",
    "                    input_data, \n",
    "                    lowcut=self.lowcut, \n",
    "                    highcut=self.highcut, \n",
    "                    fs=self.fs, \n",
    "                    order=self.order\n",
    "                )\n",
    "                \n",
    "            return input_data, target_data\n",
    "        finally:\n",
    "            del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "def format_time(elapsed):\n",
    "    \"\"\"Take a time in seconds and return a string hh:mm:ss.\"\"\"\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def seed_everything(\n",
    "    seed_value: int\n",
    ") -> None:\n",
    "\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "    if torch.backends.cudnn.is_available:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "GPU memory: 6.00GB\n",
      "\n",
      "{'data_path': '/input', 'model': {'name': 'UNet', 'unet_params': {'init_features': 32, 'depth': 5}}, 'read_weights': None, 'batch_size': 64, 'print_freq': 1000, 'max_epochs': 20, 'es_epochs': 4, 'seed': 42, 'valid_frac': 16, 'train_frac': 1, 'optimizer': {'lr': 0.0005, 'weight_decay': 0.001}, 'scheduler': {'params': {'factor': 0.316227766, 'patience': 1}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "_, total = torch.cuda.mem_get_info(device=0)\n",
    "print(f\"GPU memory: {total / 1024**3:.2f}GB\")\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as file_obj:\n",
    "    config = yaml.safe_load(file_obj)\n",
    "print()\n",
    "print(config)\n",
    "if config[\"data_path\"] is None:\n",
    "    config[\"data_path\"] = os.environ[\"TMPDIR\"]\n",
    "    print(\"data_path:\", config[\"data_path\"])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input/output files: 20\n",
      "Number of train files: 18\n",
      "Number of valid files: 2\n"
     ]
    }
   ],
   "source": [
    "# Preparation and training\n",
    "# Refactored training pipeline with denoising\n",
    "# Set random seed\n",
    "seed_everything(config[\"seed\"])\n",
    "\n",
    "# Get data files\n",
    "all_inputs, all_outputs = [], []\n",
    "for x in [\"input/train_samples\"]:\n",
    "    all_inputs1, all_outputs1 = get_train_files(x)\n",
    "    all_inputs.extend(all_inputs1)\n",
    "    all_outputs.extend(all_outputs1)\n",
    "print(\"Total number of input/output files:\", len(all_inputs))\n",
    "\n",
    "# Split into train and validation sets\n",
    "valid_inputs = [all_inputs[i] for i in range(0, len(all_inputs), config[\"valid_frac\"])]\n",
    "train_inputs = [f for f in all_inputs if not f in valid_inputs]\n",
    "if config[\"train_frac\"] > 1:\n",
    "    train_inputs = [train_inputs[i] for i in range(0, len(train_inputs), config[\"train_frac\"])]\n",
    "\n",
    "print(\"Number of train files:\", len(train_inputs))\n",
    "print(\"Number of valid files:\", len(valid_inputs))\n",
    "\n",
    "train_outputs = inputs_files_to_output_files(train_inputs)\n",
    "valid_outputs = inputs_files_to_output_files(valid_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-14T18:20:26.578Z",
     "iopub.execute_input": "2025-05-14T16:28:53.018309Z",
     "iopub.status.busy": "2025-05-14T16:28:53.017978Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01  Step 140/140  Trn Loss: 459.49  LR: 5.00e-04  GPU Usage: 6.00GB  Elapsed Time: 0:01:19\n",
      "\n",
      "Epoch: 01  Trn Loss: 459.49  Val Loss: 433.81  GPU Usage: 6.00GB  Elapsed Time: 0:01:27\n",
      "\n",
      "New best val_loss: 433.81\n",
      "\n",
      "Epoch: 02  Step 140/140  Trn Loss: 402.20  LR: 5.00e-04  GPU Usage: 6.00GB  Elapsed Time: 0:02:46\n",
      "\n",
      "Epoch: 02  Trn Loss: 402.20  Val Loss: 423.08  GPU Usage: 6.00GB  Elapsed Time: 0:02:54\n",
      "\n",
      "New best val_loss: 423.08\n",
      "\n",
      "Epoch: 03  Step 140/140  Trn Loss: 424.24  LR: 5.00e-04  GPU Usage: 6.00GB  Elapsed Time: 0:04:13\n",
      "\n",
      "Epoch: 03  Trn Loss: 424.24  Val Loss: 432.97  GPU Usage: 6.00GB  Elapsed Time: 0:04:21\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 04  Step 140/140  Trn Loss: 421.45  LR: 5.00e-04  GPU Usage: 6.00GB  Elapsed Time: 0:05:39\n",
      "\n",
      "Epoch: 04  Trn Loss: 421.45  Val Loss: 418.60  GPU Usage: 6.00GB  Elapsed Time: 0:05:47\n",
      "\n",
      "New best val_loss: 418.60\n",
      "\n",
      "Epoch: 05  Step 140/140  Trn Loss: 418.38  LR: 5.00e-04  GPU Usage: 6.00GB  Elapsed Time: 0:07:07\n",
      "\n",
      "Epoch: 05  Trn Loss: 418.38  Val Loss: 416.45  GPU Usage: 6.00GB  Elapsed Time: 0:07:15\n",
      "\n",
      "New best val_loss: 416.45\n",
      "\n",
      "Epoch: 06  Step 140/140  Trn Loss: 410.25  LR: 5.00e-04  GPU Usage: 6.00GB  Elapsed Time: 0:08:34\n",
      "\n",
      "Epoch: 06  Trn Loss: 410.25  Val Loss: 393.56  GPU Usage: 6.00GB  Elapsed Time: 0:08:42\n",
      "\n",
      "New best val_loss: 393.56\n",
      "\n",
      "Epoch: 07  Step 140/140  Trn Loss: 398.74  LR: 5.00e-04  GPU Usage: 6.00GB  Elapsed Time: 0:10:00\n",
      "\n",
      "Epoch: 07  Trn Loss: 398.74  Val Loss: 407.16  GPU Usage: 6.00GB  Elapsed Time: 0:10:08\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 08  Step 140/140  Trn Loss: 396.80  LR: 5.00e-04  GPU Usage: 6.00GB  Elapsed Time: 0:11:25\n",
      "\n",
      "Epoch: 08  Trn Loss: 396.80  Val Loss: 372.24  GPU Usage: 6.00GB  Elapsed Time: 0:11:33\n",
      "\n",
      "New best val_loss: 372.24\n",
      "\n",
      "Epoch: 09  Step 140/140  Trn Loss: 389.72  LR: 5.00e-04  GPU Usage: 6.00GB  Elapsed Time: 0:12:50\n",
      "\n",
      "Epoch: 09  Trn Loss: 389.72  Val Loss: 367.25  GPU Usage: 6.00GB  Elapsed Time: 0:12:58\n",
      "\n",
      "New best val_loss: 367.25\n",
      "\n",
      "Epoch: 10  Step 140/140  Trn Loss: 388.18  LR: 5.00e-04  GPU Usage: 6.00GB  Elapsed Time: 0:14:16\n",
      "\n",
      "Epoch: 10  Trn Loss: 388.18  Val Loss: 382.99  GPU Usage: 6.00GB  Elapsed Time: 0:14:24\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 11  Step 140/140  Trn Loss: 381.02  LR: 5.00e-04  GPU Usage: 6.00GB  Elapsed Time: 0:15:41\n",
      "\n",
      "Epoch: 11  Trn Loss: 381.02  Val Loss: 405.65  GPU Usage: 6.00GB  Elapsed Time: 0:15:49\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 12  Step 140/140  Trn Loss: 382.51  LR: 1.58e-04  GPU Usage: 6.00GB  Elapsed Time: 0:17:06\n",
      "\n",
      "Epoch: 12  Trn Loss: 382.51  Val Loss: 354.62  GPU Usage: 6.00GB  Elapsed Time: 0:17:14\n",
      "\n",
      "New best val_loss: 354.62\n",
      "\n",
      "Epoch: 13  Step 140/140  Trn Loss: 349.96  LR: 1.58e-04  GPU Usage: 6.00GB  Elapsed Time: 0:18:31\n",
      "\n",
      "Epoch: 13  Trn Loss: 349.96  Val Loss: 350.58  GPU Usage: 6.00GB  Elapsed Time: 0:18:39\n",
      "\n",
      "New best val_loss: 350.58\n",
      "\n",
      "Epoch: 14  Step 140/140  Trn Loss: 335.14  LR: 1.58e-04  GPU Usage: 6.00GB  Elapsed Time: 0:19:57\n",
      "\n",
      "Epoch: 14  Trn Loss: 335.14  Val Loss: 361.07  GPU Usage: 6.00GB  Elapsed Time: 0:20:05\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 15  Step 140/140  Trn Loss: 326.75  LR: 1.58e-04  GPU Usage: 6.00GB  Elapsed Time: 0:21:21\n",
      "\n",
      "Epoch: 15  Trn Loss: 326.75  Val Loss: 363.21  GPU Usage: 6.00GB  Elapsed Time: 0:21:29\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 16  Step 140/140  Trn Loss: 327.93  LR: 5.00e-05  GPU Usage: 6.00GB  Elapsed Time: 0:22:46\n",
      "\n",
      "Epoch: 16  Trn Loss: 327.93  Val Loss: 344.04  GPU Usage: 6.00GB  Elapsed Time: 0:22:54\n",
      "\n",
      "New best val_loss: 344.04\n",
      "\n",
      "Epoch: 17  Step 140/140  Trn Loss: 316.13  LR: 5.00e-05  GPU Usage: 6.00GB  Elapsed Time: 0:24:12\n",
      "\n",
      "Epoch: 17  Trn Loss: 316.13  Val Loss: 327.27  GPU Usage: 6.00GB  Elapsed Time: 0:24:20\n",
      "\n",
      "New best val_loss: 327.27\n",
      "\n",
      "Epoch: 18  Step 140/140  Trn Loss: 310.60  LR: 5.00e-05  GPU Usage: 6.00GB  Elapsed Time: 0:25:37\n",
      "\n",
      "Epoch: 18  Trn Loss: 310.60  Val Loss: 319.65  GPU Usage: 6.00GB  Elapsed Time: 0:25:45\n",
      "\n",
      "New best val_loss: 319.65\n",
      "\n",
      "Epoch: 19  Step 140/140  Trn Loss: 306.21  LR: 5.00e-05  GPU Usage: 6.00GB  Elapsed Time: 0:27:02\n",
      "\n",
      "Epoch: 19  Trn Loss: 306.21  Val Loss: 313.32  GPU Usage: 6.00GB  Elapsed Time: 0:27:10\n",
      "\n",
      "New best val_loss: 313.32\n",
      "\n",
      "Epoch: 20  Step 140/140  Trn Loss: 302.25  LR: 5.00e-05  GPU Usage: 6.00GB  Elapsed Time: 0:28:27\n",
      "\n",
      "Epoch: 20  Trn Loss: 302.25  Val Loss: 306.48  GPU Usage: 6.00GB  Elapsed Time: 0:28:35\n",
      "\n",
      "New best val_loss: 306.48\n",
      "\n",
      "\n",
      "==================================================\n",
      "MODEL TRAINING COMPLETE\n",
      "==================================================\n",
      "\n",
      "Model Summary:\n",
      "Architecture: UNet\n",
      "Total parameters: 52,079,841\n",
      "Trainable parameters: 52,079,841\n",
      "Best validation loss: 306.4837\n",
      "Total training time: 0:28:36\n",
      "\n",
      "Model Structure:\n",
      "UNet(\n",
      "  (initial_pool): AvgPool2d(kernel_size=(14, 1), stride=(14, 1), padding=0)\n",
      "  (encoder_convs): ModuleList(\n",
      "    (0): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder_pools): ModuleList(\n",
      "    (0-4): 5 x MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (inc): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Identity()\n",
      "  )\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Create datasets without denoising for training\n",
    "dstrain = SeismicDataset(  # Use the original SeismicDataset instead of DenoisedSeismicDataset\n",
    "    train_inputs, \n",
    "    train_outputs\n",
    ")\n",
    "\n",
    "dltrain = DataLoader(\n",
    "    dstrain,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    "    num_workers=0,  # Changed to 0 to completely disable multiprocessing for debugging\n",
    "    persistent_workers=False,\n",
    ")\n",
    "\n",
    "# For validation, also use the original dataset without denoising\n",
    "dsvalid = SeismicDataset(  # Use the original SeismicDataset\n",
    "    valid_inputs, \n",
    "    valid_outputs\n",
    ")\n",
    "\n",
    "dlvalid = DataLoader(\n",
    "    dsvalid,\n",
    "    batch_size=4*config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,  # Changed to 0 to completely disable multiprocessing\n",
    "    persistent_workers=False,  # Changed to False to match the training loader\n",
    ")\n",
    "\n",
    "# Set up device, model, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(**config[\"model\"][\"unet_params\"]).to(device)\n",
    "\n",
    "if config[\"read_weights\"] is not None:\n",
    "    print(\"Reading weights from:\", config[\"read_weights\"])\n",
    "    model.load_state_dict(torch.load(config[\"read_weights\"], weights_only=True))\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), **config[\"optimizer\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', **config[\"scheduler\"][\"params\"])\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = 10000.0\n",
    "epochs_wo_improvement = 0\n",
    "t0 = time.time()\n",
    "\n",
    "for epoch in range(1, config[\"max_epochs\"] + 1):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for step, (inputs, targets) in enumerate(dltrain):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        if step % config[\"print_freq\"] == config[\"print_freq\"] - 1 or step == len(dltrain) - 1:\n",
    "            trn_loss = np.mean(train_losses)\n",
    "            t1 = format_time(time.time() - t0)\n",
    "            free, total = torch.cuda.mem_get_info(device=0)\n",
    "            mem_used = (total - free) / 1024**3\n",
    "            lr = optimizer.param_groups[-1]['lr']\n",
    "            print(\n",
    "                f\"Epoch: {epoch:02d}  Step {step+1}/{len(dltrain)}  Trn Loss: {trn_loss:.2f}  LR: {lr:.2e}  GPU Usage: {mem_used:.2f}GB  Elapsed Time: {t1}\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    valid_losses = []\n",
    "    \n",
    "    for inputs, targets in dlvalid:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        valid_losses.append(loss.item())\n",
    "\n",
    "    t1 = format_time(time.time() - t0)\n",
    "    trn_loss = np.mean(train_losses)\n",
    "    val_loss = np.mean(valid_losses)\n",
    "\n",
    "    free, total = torch.cuda.mem_get_info(device=0)\n",
    "    mem_used = (total - free) / 1024**3\n",
    "\n",
    "    print(\n",
    "        f\"\\nEpoch: {epoch:02d}  Trn Loss: {trn_loss:.2f}  Val Loss: {val_loss:.2f}  GPU Usage: {mem_used:.2f}GB  Elapsed Time: {t1}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_wo_improvement = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"\\nNew best val_loss: {val_loss:.2f}\\n\", flush=True)\n",
    "    else:\n",
    "        epochs_wo_improvement += 1\n",
    "        print(f\"\\nEpochs without improvement: {epochs_wo_improvement}\\n\", flush=True)\n",
    "\n",
    "    if epochs_wo_improvement == config[\"es_epochs\"]:\n",
    "        break\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"Architecture: UNet\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Total training time: {format_time(time.time() - t0)}\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\nModel Structure:\")\n",
    "print(model)\n",
    "print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n",
      "Architecture: UNet\n",
      "Total parameters: 52,079,841\n",
      "Trainable parameters: 52,079,841\n",
      "Best validation loss: 306.4837\n",
      "Total training time: 0:28:36\n",
      "\n",
      "Model Structure:\n",
      "UNet(\n",
      "  (initial_pool): AvgPool2d(kernel_size=(14, 1), stride=(14, 1), padding=0)\n",
      "  (encoder_convs): ModuleList(\n",
      "    (0): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder_pools): ModuleList(\n",
      "    (0-4): 5 x MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (inc): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Identity()\n",
      "  )\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"Architecture: UNet\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Total training time: {format_time(time.time() - t0)}\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\nModel Structure:\")\n",
    "print(model)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-14T16:28:07.669373Z",
     "iopub.status.idle": "2025-05-14T16:28:07.669589Z",
     "shell.execute_reply": "2025-05-14T16:28:07.669495Z",
     "shell.execute_reply.started": "2025-05-14T16:28:07.669486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Inference ===============\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== Inference ===============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-14T16:28:07.670246Z",
     "iopub.status.idle": "2025-05-14T16:28:07.670565Z",
     "shell.execute_reply": "2025-05-14T16:28:07.670421Z",
     "shell.execute_reply.started": "2025-05-14T16:28:07.670405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Inference\n",
    "t0 = time.time()\n",
    "\n",
    "test_files = list(Path(\"input/test\").glob(\"*.npy\"))\n",
    "x_cols = [f\"x_{i}\" for i in range(1, 70, 2)]\n",
    "fieldnames = [\"oid_ypos\"] + x_cols\n",
    "ds = TestDataset(test_files)\n",
    "dl = DataLoader(ds, batch_size=4*config[\"batch_size\"], num_workers=4, pin_memory=False)\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "\n",
    "model.eval()\n",
    "with open(\"submission.csv\", \"wt\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for inputs, oids_test in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        with torch.inference_mode():\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        y_preds = outputs[:, 0].cpu().numpy()\n",
    "\n",
    "        for y_pred, oid_test in zip(y_preds, oids_test):\n",
    "            for y_pos in range(70):\n",
    "                row = dict(zip(x_cols, [y_pred[y_pos, x_pos] for x_pos in range(1, 70, 2)]))\n",
    "                row[\"oid_ypos\"] = f\"{oid_test}_y_{y_pos}\"\n",
    "\n",
    "                writer.writerow(row)\n",
    "\n",
    "t1 = format_time(time.time() - t0)\n",
    "print(f\"Inference Time: {t1}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11756775,
     "sourceId": 39763,
     "sourceType": "competition"
    },
    {
     "datasetId": 7253205,
     "sourceId": 11568812,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7253605,
     "sourceId": 11569667,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7253661,
     "sourceId": 11569755,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
