{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T14:53:18.823481Z",
     "iopub.status.busy": "2025-04-25T14:53:18.823205Z",
     "iopub.status.idle": "2025-04-25T14:53:23.506381Z",
     "shell.execute_reply": "2025-04-25T14:53:23.505626Z",
     "shell.execute_reply.started": "2025-04-25T14:53:18.823463Z"
    }
   },
   "source": [
    "# Improved UNet pipepline with larger dataset - Copied Notebook with Modifications\n",
    "\n",
    "#### [<u>Initial version</u>](https://www.kaggle.com/code/egortrushin/gwi-improved-unet-pipepline-with-larger-dataset)\n",
    "\n",
    "- We used UNet model as introduced in [<u>5 depth U net with residual</u>](https://www.kaggle.com/code/adhok93/5-depth-u-net-with-residual) Notebook.\n",
    "- We used part of Full OpenWFI dataset, which was introduced in [<u>OpenFWI InversionNet Train with 670G Datasets</u>](https://www.kaggle.com/code/seshurajup/openfwi-inversionnet-train-with-670g-datasets) Notebook.\n",
    "\n",
    "#### <u>Copied version</u>\n",
    "\n",
    "- We will use openFWI dataset converted from float32 to float16 ([<u>openfwi_float16_1</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-1), [<u>openfwi_float16_2</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-2), and [<u>openfwi_float16_test</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-test)). Since reading of data from disk is a bottleneck here, the conversion allows us to read data from disk twice faster and to use twice more data in training for the same runtime.\n",
    "\n",
    "#### <u>Added Processing version</u>\n",
    "\n",
    "- I have added denoising and normalization to see if "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:02.356186Z",
     "iopub.status.busy": "2025-05-14T16:28:02.355913Z",
     "iopub.status.idle": "2025-05-14T16:28:02.366251Z",
     "shell.execute_reply": "2025-05-14T16:28:02.365259Z",
     "shell.execute_reply.started": "2025-05-14T16:28:02.356159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "data_path: /input\n",
    "model: \n",
    "    name: UNet\n",
    "    unet_params:\n",
    "        init_features: 32\n",
    "        depth: 5\n",
    "read_weights: null\n",
    "batch_size: 32\n",
    "print_freq: 1000\n",
    "max_epochs: 30\n",
    "es_epochs: 4\n",
    "seed: 42\n",
    "valid_frac: 16\n",
    "train_frac: 2\n",
    "optimizer:\n",
    "    lr: 0.0005\n",
    "    weight_decay: 0.001\n",
    "scheduler:\n",
    "    params:\n",
    "        factor: 0.316227766\n",
    "        patience: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, filtfilt, sosfilt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_sharing_strategy('file_system')\n",
    "\n",
    "# Utilities\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:02.367961Z",
     "iopub.status.busy": "2025-05-14T16:28:02.367746Z",
     "iopub.status.idle": "2025-05-14T16:28:06.750047Z",
     "shell.execute_reply": "2025-05-14T16:28:06.749262Z",
     "shell.execute_reply.started": "2025-05-14T16:28:02.367942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "def inputs_files_to_output_files(input_files):\n",
    "    return [\n",
    "        Path(str(f).replace('seis', 'vel').replace('data', 'model'))\n",
    "        for f in input_files\n",
    "    ]\n",
    "\n",
    "def get_train_files(data_path):\n",
    "\n",
    "    all_inputs = [\n",
    "        f\n",
    "        for f in\n",
    "        Path(data_path).rglob('*.npy')\n",
    "        if ('seis' in f.stem) or ('data' in f.stem)\n",
    "    ]\n",
    "\n",
    "    all_outputs = inputs_files_to_output_files(all_inputs)\n",
    "\n",
    "    assert all(f.exists() for f in all_outputs)\n",
    "\n",
    "    return all_inputs, all_outputs\n",
    "\n",
    "class SeismicDataset(Dataset):\n",
    "    def __init__(self, inputs_files, output_files, n_examples_per_file=500):\n",
    "        assert len(inputs_files) == len(output_files)\n",
    "        self.inputs_files = inputs_files\n",
    "        self.output_files = output_files\n",
    "        self.n_examples_per_file = n_examples_per_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_files) * self.n_examples_per_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate file offset and sample offset within file\n",
    "        file_idx = idx // self.n_examples_per_file\n",
    "        sample_idx = idx % self.n_examples_per_file\n",
    "\n",
    "        X = np.load(self.inputs_files[file_idx], mmap_mode='r')\n",
    "        y = np.load(self.output_files[file_idx], mmap_mode='r')\n",
    "\n",
    "        try:\n",
    "            return X[sample_idx].copy(), y[sample_idx].copy()\n",
    "        finally:\n",
    "            del X, y\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_files):\n",
    "        self.test_files = test_files\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        test_file = self.test_files[i]\n",
    "\n",
    "        return np.load(test_file), test_file.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:06.751541Z",
     "iopub.status.busy": "2025-05-14T16:28:06.751295Z",
     "iopub.status.idle": "2025-05-14T16:28:06.773854Z",
     "shell.execute_reply": "2025-05-14T16:28:06.773264Z",
     "shell.execute_reply.started": "2025-05-14T16:28:06.751525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class ResidualDoubleConv(nn.Module):\n",
    "    \"\"\"(Convolution => [BN] => ReLU) * 2 + Residual Connection\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "\n",
    "        # First convolution layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Second convolution layer\n",
    "        self.conv2 = nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Shortcut connection to handle potential channel mismatch\n",
    "        if in_channels == out_channels:\n",
    "            self.shortcut = nn.Identity()\n",
    "        else:\n",
    "            # Projection shortcut: 1x1 conv + BN to match output channels\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # Store the input for the residual connection\n",
    "\n",
    "        # First conv block\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # Second conv block (without final ReLU yet)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Apply shortcut to the identity path\n",
    "        identity_mapped = self.shortcut(identity)\n",
    "\n",
    "        # Add the residual connection\n",
    "        out += identity_mapped\n",
    "\n",
    "        # Apply final ReLU\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then ResidualDoubleConv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "            # Input to ResidualDoubleConv = channels from upsampled layer below + channels from skip connection\n",
    "            # Output of ResidualDoubleConv = desired output channels for this decoder stage\n",
    "            self.conv = ResidualDoubleConv(in_channels + out_channels, out_channels) # Use ResidualDoubleConv\n",
    "\n",
    "        else: # Using ConvTranspose2d\n",
    "            # ConvTranspose halves the channels: in_channels -> in_channels // 2\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            # Input channels to ResidualDoubleConv\n",
    "            conv_in_channels = in_channels // 2 # Channels after ConvTranspose\n",
    "            skip_channels = out_channels       # Channels from skip connection\n",
    "            total_in_channels = conv_in_channels + skip_channels\n",
    "            self.conv = ResidualDoubleConv(total_in_channels, out_channels) # Use ResidualDoubleConv\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # x1 is the feature map from the layer below (needs upsampling)\n",
    "        # x2 is the skip connection from the corresponding encoder layer\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        # Pad x1 if its dimensions don't match x2 after upsampling\n",
    "        # Input is CHW\n",
    "        diffY = x2.size(2) - x1.size(2)\n",
    "        diffX = x2.size(3) - x1.size(3)\n",
    "\n",
    "        # Pad format: (padding_left, padding_right, padding_top, padding_bottom)\n",
    "        x1 = F.pad(\n",
    "            x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2]\n",
    "        )\n",
    "\n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"1x1 Convolution for the output layer\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net architecture implementation with Residual Blocks\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_channels=5,\n",
    "        n_classes=1,\n",
    "        init_features=32,\n",
    "        depth=5, # number of pooling layers\n",
    "        bilinear=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.depth = depth\n",
    "\n",
    "        self.initial_pool = nn.AvgPool2d(kernel_size=(14, 1), stride=(14, 1))\n",
    "\n",
    "        # --- Encoder ---\n",
    "        self.encoder_convs = nn.ModuleList() # Store conv blocks\n",
    "        self.encoder_pools = nn.ModuleList() # Store pool layers\n",
    "\n",
    "        # Initial conv block (no pooling before it)\n",
    "        # Use ResidualDoubleConv for the initial convolution block\n",
    "        self.inc = ResidualDoubleConv(n_channels, init_features)\n",
    "        self.encoder_convs.append(self.inc)\n",
    "\n",
    "        current_features = init_features\n",
    "        for _ in range(depth):\n",
    "            # Define convolution block for this stage\n",
    "            conv = ResidualDoubleConv(current_features, current_features * 2)\n",
    "            # Define pooling layer for this stage\n",
    "            pool = nn.MaxPool2d(2)\n",
    "            self.encoder_convs.append(conv)\n",
    "            self.encoder_pools.append(pool)\n",
    "            current_features *= 2\n",
    "\n",
    "        # --- Bottleneck ---\n",
    "        # Use ResidualDoubleConv for the bottleneck\n",
    "        self.bottleneck = ResidualDoubleConv(current_features, current_features)\n",
    "\n",
    "        # --- Decoder ---\n",
    "        self.decoder_blocks = nn.ModuleList()\n",
    "        # Input features start from bottleneck output features\n",
    "        # Output features at each stage are halved\n",
    "        for _ in range(depth):\n",
    "            # Up block uses ResidualDoubleConv internally and handles channels\n",
    "            up_block = Up(current_features, current_features // 2, bilinear)\n",
    "            self.decoder_blocks.append(up_block)\n",
    "            current_features //= 2 # Halve features for next Up block input\n",
    "\n",
    "        # --- Output Layer ---\n",
    "        # Input features are the output features of the last Up block\n",
    "        self.outc = OutConv(current_features, n_classes)\n",
    "\n",
    "    def _pad_or_crop(self, x, target_h=70, target_w=70):\n",
    "        \"\"\"Pads or crops input tensor x to target height and width.\"\"\"\n",
    "        _, _, h, w = x.shape\n",
    "        # Pad Height if needed\n",
    "        if h < target_h:\n",
    "            pad_top = (target_h - h) // 2\n",
    "            pad_bottom = target_h - h - pad_top\n",
    "            x = F.pad(x, (0, 0, pad_top, pad_bottom))  # Pad height only\n",
    "            h = target_h\n",
    "        # Pad Width if needed\n",
    "        if w < target_w:\n",
    "            pad_left = (target_w - w) // 2\n",
    "            pad_right = target_w - w - pad_left\n",
    "            x = F.pad(x, (pad_left, pad_right, 0, 0))  # Pad width only\n",
    "            w = target_w\n",
    "        # Crop Height if needed\n",
    "        if h > target_h:\n",
    "            crop_top = (h - target_h) // 2\n",
    "            # Use slicing to crop\n",
    "            x = x[:, :, crop_top : crop_top + target_h, :]\n",
    "            h = target_h\n",
    "        # Crop Width if needed\n",
    "        if w > target_w:\n",
    "            crop_left = (w - target_w) // 2\n",
    "            x = x[:, :, :, crop_left : crop_left + target_w]\n",
    "            w = target_w\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial pooling and resizing\n",
    "        x_pooled = self.initial_pool(x)\n",
    "        x_resized = self._pad_or_crop(x_pooled, target_h=70, target_w=70)\n",
    "\n",
    "        # --- Encoder Path ---\n",
    "        skip_connections = []\n",
    "        xi = x_resized\n",
    "\n",
    "        # Apply initial conv (inc)\n",
    "        xi = self.encoder_convs[0](xi)\n",
    "        skip_connections.append(xi) # Store output of inc\n",
    "\n",
    "        # Apply subsequent encoder convs and pools\n",
    "        # self.depth is the number of pooling layers\n",
    "        for i in range(self.depth):\n",
    "            # Apply conv block for this stage\n",
    "            xi = self.encoder_convs[i+1](xi)\n",
    "            # Store skip connection *before* pooling\n",
    "            skip_connections.append(xi)\n",
    "            # Apply pooling layer for this stage\n",
    "            xi = self.encoder_pools[i](xi)\n",
    "\n",
    "        # Apply bottleneck conv\n",
    "        xi = self.bottleneck(xi)\n",
    "\n",
    "        # --- Decoder Path ---\n",
    "        xu = xi # Start with bottleneck output\n",
    "        # Iterate through decoder blocks and corresponding skip connections in reverse\n",
    "        for i, block in enumerate(self.decoder_blocks):\n",
    "            # Determine the correct skip connection index from the end\n",
    "            # Example: depth=5. Skips stored: [inc, enc1, enc2, enc3, enc4] (indices 0-4)\n",
    "            # Decoder 0 (Up(1024, 512)) needs skip 4 (enc4)\n",
    "            # Decoder 1 (Up(512, 256)) needs skip 3 (enc3) ...\n",
    "            # Decoder 4 (Up(64, 32)) needs skip 0 (inc)\n",
    "            skip_index = self.depth - 1 - i\n",
    "            skip = skip_connections[skip_index]\n",
    "            xu = block(xu, skip) # Up block combines xu (from below) and skip\n",
    "\n",
    "        # --- Final Output ---\n",
    "        logits = self.outc(xu)\n",
    "        # Apply scaling and offset specific to the problem's target range\n",
    "        output = logits * 1000.0 + 1500.0\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T16:28:06.775018Z",
     "iopub.status.busy": "2025-05-14T16:28:06.774813Z",
     "iopub.status.idle": "2025-05-14T16:28:06.800170Z",
     "shell.execute_reply": "2025-05-14T16:28:06.799440Z",
     "shell.execute_reply.started": "2025-05-14T16:28:06.775002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "def butter_bandpass(lowcut, highcut, fs, order=2):\n",
    "    \"\"\"Design a Butterworth bandpass filter.\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band', output='ba')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    \"\"\"Apply a Butterworth bandpass filter to a 1D signal.\"\"\"\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def denoise_seismic_with_bandpass(data, lowcut=0.01, highcut=0.3, fs=1.2, order=2):\n",
    "    \"\"\"\n",
    "    Apply Butterworth bandpass filter to seismic data.\n",
    "    Handles 2D, 3D, or 4D data.\n",
    "    Inner tqdm progress bars are disabled to reduce verbosity.\n",
    "    \"\"\"\n",
    "    original_shape = data.shape\n",
    "    \n",
    "    if len(original_shape) == 4: # 4D data (e.g., batch, channels, height, width)\n",
    "        denoised_data = np.zeros_like(data)\n",
    "        # Iterate through the first dimension (samples in batch)\n",
    "        for s_idx in tqdm(range(original_shape[0]), desc=\"Processing samples in batch\", leave=False, disable=True):\n",
    "            for c_idx in range(original_shape[1]): # Channels\n",
    "                denoised_data[s_idx, c_idx] = denoise_seismic_with_bandpass(\n",
    "                    data[s_idx, c_idx], lowcut, highcut, fs, order\n",
    "                )\n",
    "        return denoised_data\n",
    "    \n",
    "    elif len(original_shape) == 3: # 3D data (e.g., batch/channels, height, width)\n",
    "        denoised_data = np.zeros_like(data)\n",
    "        # Iterate through the first dimension (channels or slices)\n",
    "        for c_idx in tqdm(range(original_shape[0]), desc=\"Processing channels/slices\", leave=False, disable=True):\n",
    "            denoised_data[c_idx] = denoise_seismic_with_bandpass(\n",
    "                data[c_idx], lowcut, highcut, fs, order\n",
    "            )\n",
    "        return denoised_data\n",
    "    \n",
    "    elif len(original_shape) == 2: # 2D data (height, width) - filter per trace\n",
    "        denoised_data = np.zeros_like(data)\n",
    "        for i in range(data.shape[1]): # Iterate over traces (width)\n",
    "            trace = data[:, i]\n",
    "            # filtfilt requirement: signal length > 3 * filter order\n",
    "            if len(trace) > order * 3:\n",
    "                 denoised_data[:, i] = butter_bandpass_filter(trace, lowcut, highcut, fs, order)\n",
    "            else:\n",
    "                # To avoid verbose output, this warning is kept as a comment.\n",
    "                # print(f\"Warning: Trace length ({len(trace)}) for trace {i} too short for filter order ({order}). Copying original trace.\")\n",
    "                denoised_data[:, i] = trace\n",
    "        return denoised_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported data shape: {original_shape}. Expected 2D, 3D, or 4D.\")\n",
    "\n",
    "# Revised memory-efficient function with reduced print output\n",
    "def denoise_training_dataset_memory_efficient(train_loader, lowcut=0.01, highcut=0.3, fs=1.2, order=2):\n",
    "    denoised_inputs_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    print(\"Starting memory-efficient denoising process...\")\n",
    "    \n",
    "    try:\n",
    "        total_batches = len(train_loader)\n",
    "    except TypeError:\n",
    "        total_batches = None \n",
    "\n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    # This is the main progress bar the user will see, updating per batch\n",
    "    for inputs_batch, targets_batch in tqdm(train_loader, desc=\"Denoising batches\", total=total_batches, unit=\"batch\"):\n",
    "        inputs_batch_np = inputs_batch.numpy() \n",
    "        \n",
    "        denoised_batch = denoise_seismic_with_bandpass(\n",
    "            inputs_batch_np, lowcut=lowcut, highcut=highcut, fs=fs, order=order\n",
    "        )\n",
    "\n",
    "        denoised_inputs_list.append(denoised_batch)\n",
    "        targets_list.append(targets_batch.numpy()) \n",
    "    \n",
    "    overall_elapsed_time = time.time() - overall_start_time\n",
    "    # Adding a newline to ensure this print is on a new line after tqdm finishes\n",
    "    print(f\"\\nAll batches processed in {overall_elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    print(\"Concatenating denoised batches and targets...\")\n",
    "    concatenation_start_time = time.time()\n",
    "    \n",
    "    final_denoised_inputs = np.concatenate(denoised_inputs_list, axis=0)\n",
    "    final_targets = np.concatenate(targets_list, axis=0)\n",
    "    \n",
    "    concatenation_elapsed_time = time.time() - concatenation_start_time\n",
    "    print(f\"Concatenation completed in {concatenation_elapsed_time:.2f} seconds.\")\n",
    "    \n",
    "    return final_denoised_inputs, final_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a custom dataset that applies denoising on-the-fly\n",
    "class DenoisedSeismicDataset(Dataset):\n",
    "    def __init__(self, inputs_files, output_files, n_examples_per_file=500, \n",
    "                 apply_denoising=True, lowcut=0.01, highcut=0.3, fs=1.2, order=2):\n",
    "        assert len(inputs_files) == len(output_files)\n",
    "        self.inputs_files = inputs_files\n",
    "        self.output_files = output_files\n",
    "        self.n_examples_per_file = n_examples_per_file\n",
    "        self.apply_denoising = apply_denoising\n",
    "        self.lowcut = lowcut\n",
    "        self.highcut = highcut\n",
    "        self.fs = fs\n",
    "        self.order = order\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_files) * self.n_examples_per_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate file offset and sample offset within file\n",
    "        file_idx = idx // self.n_examples_per_file\n",
    "        sample_idx = idx % self.n_examples_per_file\n",
    "\n",
    "        X = np.load(self.inputs_files[file_idx], mmap_mode='r')\n",
    "        y = np.load(self.output_files[file_idx], mmap_mode='r')\n",
    "\n",
    "        try:\n",
    "            input_data = X[sample_idx].copy()\n",
    "            target_data = y[sample_idx].copy()\n",
    "            \n",
    "            # Apply denoising if enabled\n",
    "            if self.apply_denoising:\n",
    "                input_data = denoise_seismic_with_bandpass(\n",
    "                    input_data, \n",
    "                    lowcut=self.lowcut, \n",
    "                    highcut=self.highcut, \n",
    "                    fs=self.fs, \n",
    "                    order=self.order\n",
    "                )\n",
    "                \n",
    "            return input_data, target_data\n",
    "        finally:\n",
    "            del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check available disk space\n",
    "def check_available_disk_space(required_gb, save_dir):\n",
    "    \"\"\"Check if there's enough disk space available.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    disk_usage = shutil.disk_usage(save_dir)\n",
    "    available_gb = disk_usage.free / (1024**3)\n",
    "    \n",
    "    print(f\"Available disk space: {available_gb:.2f} GB\")\n",
    "    print(f\"Required disk space: {required_gb:.2f} GB\")\n",
    "    \n",
    "    return available_gb >= required_gb\n",
    "\n",
    "# Function to denoise and save the dataset\n",
    "def denoise_and_save_dataset(input_files, output_files, save_dir, \n",
    "                            lowcut=0.01, highcut=0.3, fs=1.2, order=2,\n",
    "                            prefix=\"train\"):\n",
    "    \"\"\"Process all files, apply denoising, and save to disk.\"\"\"\n",
    "    # Create directory for denoised data\n",
    "    denoised_dir = os.path.join(save_dir, \"denoised_data\")\n",
    "    os.makedirs(denoised_dir, exist_ok=True)\n",
    "    \n",
    "    # Estimate required disk space\n",
    "    sample_input = np.load(input_files[0], mmap_mode='r')\n",
    "    sample_size_bytes = sample_input.nbytes\n",
    "    total_files = len(input_files)\n",
    "    estimated_gb = (sample_size_bytes * total_files * 2) / (1024**3)  # x2 for inputs and targets\n",
    "    \n",
    "    # Check for sufficient disk space\n",
    "    if not check_available_disk_space(estimated_gb, save_dir):\n",
    "        raise RuntimeError(f\"Not enough disk space. Need approximately {estimated_gb:.2f} GB\")\n",
    "    \n",
    "    denoised_input_paths = []\n",
    "    target_output_paths = []\n",
    "    \n",
    "    print(f\"Processing {len(input_files)} files with prefix '{prefix}'...\")\n",
    "    \n",
    "    # Process each file\n",
    "    for i, (input_file, output_file) in enumerate(tqdm(zip(input_files, output_files), \n",
    "                                                      total=len(input_files),\n",
    "                                                      desc=f\"Denoising {prefix} files\")):\n",
    "        # Generate filenames\n",
    "        base_name = os.path.basename(input_file)\n",
    "        denoised_filename = f\"{prefix}_denoised_{i}_{base_name}\"\n",
    "        target_filename = f\"{prefix}_target_{i}_{os.path.basename(output_file)}\"\n",
    "        \n",
    "        denoised_path = os.path.join(denoised_dir, denoised_filename)\n",
    "        target_path = os.path.join(denoised_dir, target_filename)\n",
    "        \n",
    "        # Add to path lists\n",
    "        denoised_input_paths.append(denoised_path)\n",
    "        target_output_paths.append(target_path)\n",
    "        \n",
    "        # Skip if files already exist\n",
    "        if os.path.exists(denoised_path) and os.path.exists(target_path):\n",
    "            print(f\"Files already exist for {base_name}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Load data\n",
    "            input_data = np.load(input_file)\n",
    "            target_data = np.load(output_file)\n",
    "            \n",
    "            # Apply denoising\n",
    "            denoised_input = denoise_seismic_with_bandpass(\n",
    "                input_data, \n",
    "                lowcut=lowcut, \n",
    "                highcut=highcut, \n",
    "                fs=fs, \n",
    "                order=order\n",
    "            )\n",
    "            \n",
    "            # Save processed data\n",
    "            np.save(denoised_path, denoised_input)\n",
    "            np.save(target_path, target_data)\n",
    "            \n",
    "            # Free memory\n",
    "            del input_data, denoised_input, target_data\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {input_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return denoised_input_paths, target_output_paths\n",
    "\n",
    "# Dataset class for pre-denoised data\n",
    "class PreDenoisedSeismicDataset(Dataset):\n",
    "    def __init__(self, inputs_files, output_files, n_examples_per_file=250):\n",
    "        assert len(inputs_files) == len(output_files)\n",
    "        self.inputs_files = inputs_files\n",
    "        self.output_files = output_files\n",
    "        self.n_examples_per_file = n_examples_per_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_files) * self.n_examples_per_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate which file and sample within file\n",
    "        file_idx = idx // self.n_examples_per_file\n",
    "        sample_idx = idx % self.n_examples_per_file\n",
    "\n",
    "        try:\n",
    "            # Use memory-mapped loading for efficiency\n",
    "            X = np.load(self.inputs_files[file_idx], mmap_mode='r')\n",
    "            y = np.load(self.output_files[file_idx], mmap_mode='r')\n",
    "            \n",
    "            # Copy to avoid memory issues with mmap\n",
    "            input_data = X[sample_idx].copy()\n",
    "            target_data = y[sample_idx].copy()\n",
    "                \n",
    "            return torch.from_numpy(input_data).float(), torch.from_numpy(target_data).float()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx} from file {self.inputs_files[file_idx]}: {str(e)}\")\n",
    "            # Return zeros with appropriate shape (adjust based on your data dimensions)\n",
    "            return torch.zeros((1, 224, 224), dtype=torch.float32), torch.zeros((1, 224, 224), dtype=torch.float32)\n",
    "        finally:\n",
    "            # Clean up memory-mapped files\n",
    "            if 'X' in locals():\n",
    "                del X\n",
    "            if 'y' in locals():\n",
    "                del y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "def format_time(elapsed):\n",
    "    \"\"\"Take a time in seconds and return a string hh:mm:ss.\"\"\"\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def seed_everything(\n",
    "    seed_value: int\n",
    ") -> None:\n",
    "\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "    if torch.backends.cudnn.is_available:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4070 SUPER\n",
      "GPU memory: 11.99GB\n",
      "\n",
      "{'data_path': '/input', 'model': {'name': 'UNet', 'unet_params': {'init_features': 32, 'depth': 5}}, 'read_weights': None, 'batch_size': 32, 'print_freq': 1000, 'max_epochs': 30, 'es_epochs': 4, 'seed': 42, 'valid_frac': 16, 'train_frac': 2, 'optimizer': {'lr': 0.0005, 'weight_decay': 0.001}, 'scheduler': {'params': {'factor': 0.316227766, 'patience': 1}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "_, total = torch.cuda.mem_get_info(device=0)\n",
    "print(f\"GPU memory: {total / 1024**3:.2f}GB\")\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as file_obj:\n",
    "    config = yaml.safe_load(file_obj)\n",
    "print()\n",
    "print(config)\n",
    "if config[\"data_path\"] is None:\n",
    "    config[\"data_path\"] = os.environ[\"TMPDIR\"]\n",
    "    print(\"data_path:\", config[\"data_path\"])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input/output files: 960\n",
      "Number of train files: 450\n",
      "Number of valid files: 60\n"
     ]
    }
   ],
   "source": [
    "# Preparation and training\n",
    "# Refactored training pipeline with pre-denoising\n",
    "# Set random seed\n",
    "seed_everything(config[\"seed\"])\n",
    "\n",
    "# Get data files\n",
    "all_inputs, all_outputs = [], []\n",
    "for x in [\"input/train_samples\", \"input\\openfwi_float16_1\", \"input\\openfwi_float16_2\"]:\n",
    "    all_inputs1, all_outputs1 = get_train_files(x)\n",
    "    all_inputs.extend(all_inputs1)\n",
    "    all_outputs.extend(all_outputs1)\n",
    "print(\"Total number of input/output files:\", len(all_inputs))\n",
    "\n",
    "# Split into train and validation sets\n",
    "valid_indices = list(range(0, len(all_inputs), config[\"valid_frac\"]))\n",
    "valid_inputs = [all_inputs[i] for i in valid_indices]\n",
    "train_inputs = [f for f in all_inputs if f not in valid_inputs]\n",
    "\n",
    "if config[\"train_frac\"] > 1:\n",
    "    train_indices = list(range(0, len(train_inputs), config[\"train_frac\"]))\n",
    "    train_inputs = [train_inputs[i] for i in train_indices]\n",
    "\n",
    "print(\"Number of train files:\", len(train_inputs))\n",
    "print(\"Number of valid files:\", len(valid_inputs))\n",
    "\n",
    "train_outputs = inputs_files_to_output_files(train_inputs)\n",
    "valid_outputs = inputs_files_to_output_files(valid_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for denoising\n",
    "denoise_params = {\n",
    "    \"lowcut\": 0.01,\n",
    "    \"highcut\": 0.3,\n",
    "    \"fs\": 1.2,\n",
    "    \"order\": 2\n",
    "}\n",
    "\n",
    "# Create directory for saving denoised data\n",
    "save_dir = config.get(\"denoised_save_dir\", \"denoised_data\")\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing and saving denoised training data...\n",
      "Available disk space: 724.56 GB\n",
      "Required disk space: 586.73 GB\n",
      "Processing 450 files with prefix 'train'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd928c7a074e411bbb6794242622fbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Denoising train files:   0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing and saving denoised validation data...\n",
      "Available disk space: 607.46 GB\n",
      "Required disk space: 78.23 GB\n",
      "Processing 60 files with prefix 'valid'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853cf1c10fbe437d83b9cc6839f84403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Denoising valid files:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process and save denoised training data\n",
    "print(\"\\nPreprocessing and saving denoised training data...\")\n",
    "denoised_train_inputs, denoised_train_outputs = denoise_and_save_dataset(\n",
    "    train_inputs, \n",
    "    train_outputs, \n",
    "    save_dir=save_dir,\n",
    "    prefix=\"train\", \n",
    "    **denoise_params\n",
    ")\n",
    "\n",
    "# Process and save denoised validation data\n",
    "print(\"\\nPreprocessing and saving denoised validation data...\")\n",
    "denoised_valid_inputs, denoised_valid_outputs = denoise_and_save_dataset(\n",
    "    valid_inputs, \n",
    "    valid_outputs, \n",
    "    save_dir=save_dir,\n",
    "    prefix=\"valid\", \n",
    "    **denoise_params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-14T18:20:26.578Z",
     "iopub.execute_input": "2025-05-14T16:28:53.018309Z",
     "iopub.status.busy": "2025-05-14T16:28:53.017978Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01  Step 1000/7031  Trn Loss: 331.80  LR: 5.00e-04  GPU Usage: 3.08GB  Elapsed Time: 0:02:08\n",
      "Epoch: 01  Step 2000/7031  Trn Loss: 303.06  LR: 5.00e-04  GPU Usage: 3.08GB  Elapsed Time: 0:04:08\n",
      "Epoch: 01  Step 3000/7031  Trn Loss: 284.72  LR: 5.00e-04  GPU Usage: 3.08GB  Elapsed Time: 0:06:09\n",
      "Epoch: 01  Step 4000/7031  Trn Loss: 270.33  LR: 5.00e-04  GPU Usage: 3.08GB  Elapsed Time: 0:08:09\n",
      "Epoch: 01  Step 5000/7031  Trn Loss: 259.23  LR: 5.00e-04  GPU Usage: 3.08GB  Elapsed Time: 0:10:09\n",
      "Epoch: 01  Step 6000/7031  Trn Loss: 250.22  LR: 5.00e-04  GPU Usage: 3.08GB  Elapsed Time: 0:12:15\n",
      "Epoch: 01  Step 7000/7031  Trn Loss: 242.71  LR: 5.00e-04  GPU Usage: 3.08GB  Elapsed Time: 0:14:16\n",
      "Epoch: 01  Step 7031/7031  Trn Loss: 242.50  LR: 5.00e-04  GPU Usage: 3.08GB  Elapsed Time: 0:14:19\n",
      "\n",
      "Epoch: 01  Trn Loss: 242.50  Val Loss: 203.92  GPU Usage: 5.27GB  Elapsed Time: 0:15:26\n",
      "\n",
      "New best val_loss: 203.92\n",
      "\n",
      "Epoch: 02  Step 1000/7031  Trn Loss: 188.42  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:17:26\n",
      "Epoch: 02  Step 2000/7031  Trn Loss: 185.46  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:19:26\n",
      "Epoch: 02  Step 3000/7031  Trn Loss: 182.96  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:21:26\n",
      "Epoch: 02  Step 4000/7031  Trn Loss: 180.78  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:23:41\n",
      "Epoch: 02  Step 5000/7031  Trn Loss: 178.88  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:25:58\n",
      "Epoch: 02  Step 6000/7031  Trn Loss: 176.93  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:28:15\n",
      "Epoch: 02  Step 7000/7031  Trn Loss: 174.87  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:30:23\n",
      "Epoch: 02  Step 7031/7031  Trn Loss: 174.83  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:30:27\n",
      "\n",
      "Epoch: 02  Trn Loss: 174.83  Val Loss: 165.29  GPU Usage: 5.27GB  Elapsed Time: 0:31:36\n",
      "\n",
      "New best val_loss: 165.29\n",
      "\n",
      "Epoch: 03  Step 1000/7031  Trn Loss: 157.87  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:33:49\n",
      "Epoch: 03  Step 2000/7031  Trn Loss: 156.93  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:36:05\n",
      "Epoch: 03  Step 3000/7031  Trn Loss: 155.91  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:38:21\n",
      "Epoch: 03  Step 4000/7031  Trn Loss: 155.27  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:40:39\n",
      "Epoch: 03  Step 5000/7031  Trn Loss: 154.30  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:42:56\n",
      "Epoch: 03  Step 6000/7031  Trn Loss: 153.36  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:45:14\n",
      "Epoch: 03  Step 7000/7031  Trn Loss: 152.58  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:47:33\n",
      "Epoch: 03  Step 7031/7031  Trn Loss: 152.56  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:47:38\n",
      "\n",
      "Epoch: 03  Trn Loss: 152.56  Val Loss: 165.75  GPU Usage: 5.27GB  Elapsed Time: 0:48:58\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 04  Step 1000/7031  Trn Loss: 142.06  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:51:16\n",
      "Epoch: 04  Step 2000/7031  Trn Loss: 141.36  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:53:36\n",
      "Epoch: 04  Step 3000/7031  Trn Loss: 141.01  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:55:52\n",
      "Epoch: 04  Step 4000/7031  Trn Loss: 140.74  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:57:56\n",
      "Epoch: 04  Step 5000/7031  Trn Loss: 140.35  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 0:59:58\n",
      "Epoch: 04  Step 6000/7031  Trn Loss: 139.80  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:02:02\n",
      "Epoch: 04  Step 7000/7031  Trn Loss: 139.31  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:04:05\n",
      "Epoch: 04  Step 7031/7031  Trn Loss: 139.29  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:04:09\n",
      "\n",
      "Epoch: 04  Trn Loss: 139.29  Val Loss: 147.19  GPU Usage: 5.27GB  Elapsed Time: 1:05:17\n",
      "\n",
      "New best val_loss: 147.19\n",
      "\n",
      "Epoch: 05  Step 1000/7031  Trn Loss: 131.65  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:07:22\n",
      "Epoch: 05  Step 2000/7031  Trn Loss: 131.30  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:09:26\n",
      "Epoch: 05  Step 3000/7031  Trn Loss: 130.94  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:11:28\n",
      "Epoch: 05  Step 4000/7031  Trn Loss: 130.67  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:13:30\n",
      "Epoch: 05  Step 5000/7031  Trn Loss: 130.50  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:15:32\n",
      "Epoch: 05  Step 6000/7031  Trn Loss: 130.36  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:17:34\n",
      "Epoch: 05  Step 7000/7031  Trn Loss: 130.03  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:19:34\n",
      "Epoch: 05  Step 7031/7031  Trn Loss: 130.01  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:19:37\n",
      "\n",
      "Epoch: 05  Trn Loss: 130.01  Val Loss: 135.73  GPU Usage: 5.27GB  Elapsed Time: 1:20:43\n",
      "\n",
      "New best val_loss: 135.73\n",
      "\n",
      "Epoch: 06  Step 1000/7031  Trn Loss: 124.34  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:22:42\n",
      "Epoch: 06  Step 2000/7031  Trn Loss: 123.66  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:24:41\n",
      "Epoch: 06  Step 3000/7031  Trn Loss: 123.80  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:26:41\n",
      "Epoch: 06  Step 4000/7031  Trn Loss: 123.44  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:28:47\n",
      "Epoch: 06  Step 5000/7031  Trn Loss: 123.18  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:31:05\n",
      "Epoch: 06  Step 6000/7031  Trn Loss: 122.90  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:33:17\n",
      "Epoch: 06  Step 7000/7031  Trn Loss: 122.76  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:35:19\n",
      "Epoch: 06  Step 7031/7031  Trn Loss: 122.77  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:35:23\n",
      "\n",
      "Epoch: 06  Trn Loss: 122.77  Val Loss: 127.59  GPU Usage: 5.27GB  Elapsed Time: 1:36:30\n",
      "\n",
      "New best val_loss: 127.59\n",
      "\n",
      "Epoch: 07  Step 1000/7031  Trn Loss: 117.41  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:38:33\n",
      "Epoch: 07  Step 2000/7031  Trn Loss: 117.46  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:40:36\n",
      "Epoch: 07  Step 3000/7031  Trn Loss: 117.75  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:42:38\n",
      "Epoch: 07  Step 4000/7031  Trn Loss: 117.57  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:44:42\n",
      "Epoch: 07  Step 5000/7031  Trn Loss: 117.39  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:46:44\n",
      "Epoch: 07  Step 6000/7031  Trn Loss: 117.17  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:48:46\n",
      "Epoch: 07  Step 7000/7031  Trn Loss: 116.94  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:50:48\n",
      "Epoch: 07  Step 7031/7031  Trn Loss: 116.95  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:50:51\n",
      "\n",
      "Epoch: 07  Trn Loss: 116.95  Val Loss: 129.76  GPU Usage: 5.27GB  Elapsed Time: 1:51:59\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 08  Step 1000/7031  Trn Loss: 112.84  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:54:00\n",
      "Epoch: 08  Step 2000/7031  Trn Loss: 112.67  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:56:04\n",
      "Epoch: 08  Step 3000/7031  Trn Loss: 112.29  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 1:58:10\n",
      "Epoch: 08  Step 4000/7031  Trn Loss: 112.33  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:00:12\n",
      "Epoch: 08  Step 5000/7031  Trn Loss: 112.13  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:02:15\n",
      "Epoch: 08  Step 6000/7031  Trn Loss: 112.05  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:04:18\n",
      "Epoch: 08  Step 7000/7031  Trn Loss: 111.98  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:06:20\n",
      "Epoch: 08  Step 7031/7031  Trn Loss: 111.95  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:06:24\n",
      "\n",
      "Epoch: 08  Trn Loss: 111.95  Val Loss: 117.63  GPU Usage: 5.27GB  Elapsed Time: 2:07:33\n",
      "\n",
      "New best val_loss: 117.63\n",
      "\n",
      "Epoch: 09  Step 1000/7031  Trn Loss: 108.06  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:09:36\n",
      "Epoch: 09  Step 2000/7031  Trn Loss: 107.41  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:11:38\n",
      "Epoch: 09  Step 3000/7031  Trn Loss: 107.71  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:13:41\n",
      "Epoch: 09  Step 4000/7031  Trn Loss: 107.69  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:15:43\n",
      "Epoch: 09  Step 5000/7031  Trn Loss: 107.76  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:17:44\n",
      "Epoch: 09  Step 6000/7031  Trn Loss: 107.64  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:19:46\n",
      "Epoch: 09  Step 7000/7031  Trn Loss: 107.64  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:21:48\n",
      "Epoch: 09  Step 7031/7031  Trn Loss: 107.65  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:21:52\n",
      "\n",
      "Epoch: 09  Trn Loss: 107.65  Val Loss: 123.92  GPU Usage: 5.27GB  Elapsed Time: 2:22:59\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 10  Step 1000/7031  Trn Loss: 103.25  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:25:01\n",
      "Epoch: 10  Step 2000/7031  Trn Loss: 103.52  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:27:02\n",
      "Epoch: 10  Step 3000/7031  Trn Loss: 103.86  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:29:04\n",
      "Epoch: 10  Step 4000/7031  Trn Loss: 103.85  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:31:06\n",
      "Epoch: 10  Step 5000/7031  Trn Loss: 103.81  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:33:07\n",
      "Epoch: 10  Step 6000/7031  Trn Loss: 103.81  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:35:09\n",
      "Epoch: 10  Step 7000/7031  Trn Loss: 103.79  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:37:11\n",
      "Epoch: 10  Step 7031/7031  Trn Loss: 103.79  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:37:14\n",
      "\n",
      "Epoch: 10  Trn Loss: 103.79  Val Loss: 115.16  GPU Usage: 5.27GB  Elapsed Time: 2:38:22\n",
      "\n",
      "New best val_loss: 115.16\n",
      "\n",
      "Epoch: 11  Step 1000/7031  Trn Loss: 99.91  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:40:23\n",
      "Epoch: 11  Step 2000/7031  Trn Loss: 100.00  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:42:25\n",
      "Epoch: 11  Step 3000/7031  Trn Loss: 100.03  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:44:26\n",
      "Epoch: 11  Step 4000/7031  Trn Loss: 100.20  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:46:27\n",
      "Epoch: 11  Step 5000/7031  Trn Loss: 100.18  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:48:28\n",
      "Epoch: 11  Step 6000/7031  Trn Loss: 100.33  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:50:30\n",
      "Epoch: 11  Step 7000/7031  Trn Loss: 100.32  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:52:31\n",
      "Epoch: 11  Step 7031/7031  Trn Loss: 100.32  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:52:35\n",
      "\n",
      "Epoch: 11  Trn Loss: 100.32  Val Loss: 112.90  GPU Usage: 5.27GB  Elapsed Time: 2:53:42\n",
      "\n",
      "New best val_loss: 112.90\n",
      "\n",
      "Epoch: 12  Step 1000/7031  Trn Loss: 96.14  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:55:44\n",
      "Epoch: 12  Step 2000/7031  Trn Loss: 96.52  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:57:46\n",
      "Epoch: 12  Step 3000/7031  Trn Loss: 96.79  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 2:59:48\n",
      "Epoch: 12  Step 4000/7031  Trn Loss: 96.75  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:01:50\n",
      "Epoch: 12  Step 5000/7031  Trn Loss: 96.86  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:03:51\n",
      "Epoch: 12  Step 6000/7031  Trn Loss: 96.98  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:05:53\n",
      "Epoch: 12  Step 7000/7031  Trn Loss: 97.05  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:07:55\n",
      "Epoch: 12  Step 7031/7031  Trn Loss: 97.05  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:07:59\n",
      "\n",
      "Epoch: 12  Trn Loss: 97.05  Val Loss: 114.47  GPU Usage: 5.27GB  Elapsed Time: 3:09:06\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 13  Step 1000/7031  Trn Loss: 92.99  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:11:08\n",
      "Epoch: 13  Step 2000/7031  Trn Loss: 93.55  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:13:09\n",
      "Epoch: 13  Step 3000/7031  Trn Loss: 93.53  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:15:10\n",
      "Epoch: 13  Step 4000/7031  Trn Loss: 93.80  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:17:11\n",
      "Epoch: 13  Step 5000/7031  Trn Loss: 94.04  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:19:13\n",
      "Epoch: 13  Step 6000/7031  Trn Loss: 94.11  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:21:14\n",
      "Epoch: 13  Step 7000/7031  Trn Loss: 94.11  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:23:15\n",
      "Epoch: 13  Step 7031/7031  Trn Loss: 94.11  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:23:19\n",
      "\n",
      "Epoch: 13  Trn Loss: 94.11  Val Loss: 109.59  GPU Usage: 5.27GB  Elapsed Time: 3:24:26\n",
      "\n",
      "New best val_loss: 109.59\n",
      "\n",
      "Epoch: 14  Step 1000/7031  Trn Loss: 90.68  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:26:28\n",
      "Epoch: 14  Step 2000/7031  Trn Loss: 90.93  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:28:30\n",
      "Epoch: 14  Step 3000/7031  Trn Loss: 91.27  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:30:32\n",
      "Epoch: 14  Step 4000/7031  Trn Loss: 91.39  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:32:34\n",
      "Epoch: 14  Step 5000/7031  Trn Loss: 91.50  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:34:36\n",
      "Epoch: 14  Step 6000/7031  Trn Loss: 91.53  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:36:37\n",
      "Epoch: 14  Step 7000/7031  Trn Loss: 91.57  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:38:39\n",
      "Epoch: 14  Step 7031/7031  Trn Loss: 91.58  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:38:43\n",
      "\n",
      "Epoch: 14  Trn Loss: 91.58  Val Loss: 107.83  GPU Usage: 5.27GB  Elapsed Time: 3:39:51\n",
      "\n",
      "New best val_loss: 107.83\n",
      "\n",
      "Epoch: 15  Step 1000/7031  Trn Loss: 88.40  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:41:53\n",
      "Epoch: 15  Step 2000/7031  Trn Loss: 88.63  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:43:55\n",
      "Epoch: 15  Step 3000/7031  Trn Loss: 88.71  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:45:57\n",
      "Epoch: 15  Step 4000/7031  Trn Loss: 88.88  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:47:58\n",
      "Epoch: 15  Step 5000/7031  Trn Loss: 88.99  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:50:00\n",
      "Epoch: 15  Step 6000/7031  Trn Loss: 89.05  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:52:02\n",
      "Epoch: 15  Step 7000/7031  Trn Loss: 89.17  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:54:04\n",
      "Epoch: 15  Step 7031/7031  Trn Loss: 89.17  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:54:08\n",
      "\n",
      "Epoch: 15  Trn Loss: 89.17  Val Loss: 117.22  GPU Usage: 5.27GB  Elapsed Time: 3:55:15\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 16  Step 1000/7031  Trn Loss: 86.17  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:57:16\n",
      "Epoch: 16  Step 2000/7031  Trn Loss: 86.83  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 3:59:18\n",
      "Epoch: 16  Step 3000/7031  Trn Loss: 86.71  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 4:01:19\n",
      "Epoch: 16  Step 4000/7031  Trn Loss: 86.68  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 4:03:21\n",
      "Epoch: 16  Step 5000/7031  Trn Loss: 86.69  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 4:05:28\n",
      "Epoch: 16  Step 6000/7031  Trn Loss: 86.85  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 4:07:29\n",
      "Epoch: 16  Step 7000/7031  Trn Loss: 86.97  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 4:09:30\n",
      "Epoch: 16  Step 7031/7031  Trn Loss: 86.98  LR: 5.00e-04  GPU Usage: 5.27GB  Elapsed Time: 4:09:34\n",
      "\n",
      "Epoch: 16  Trn Loss: 86.98  Val Loss: 114.08  GPU Usage: 5.27GB  Elapsed Time: 4:10:42\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 17  Step 1000/7031  Trn Loss: 78.07  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:12:43\n",
      "Epoch: 17  Step 2000/7031  Trn Loss: 77.53  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:14:45\n",
      "Epoch: 17  Step 3000/7031  Trn Loss: 77.11  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:16:46\n",
      "Epoch: 17  Step 4000/7031  Trn Loss: 76.75  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:18:47\n",
      "Epoch: 17  Step 5000/7031  Trn Loss: 76.42  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:20:48\n",
      "Epoch: 17  Step 6000/7031  Trn Loss: 76.26  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:22:50\n",
      "Epoch: 17  Step 7000/7031  Trn Loss: 76.12  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:24:51\n",
      "Epoch: 17  Step 7031/7031  Trn Loss: 76.11  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:24:55\n",
      "\n",
      "Epoch: 17  Trn Loss: 76.11  Val Loss: 100.10  GPU Usage: 5.27GB  Elapsed Time: 4:26:02\n",
      "\n",
      "New best val_loss: 100.10\n",
      "\n",
      "Epoch: 18  Step 1000/7031  Trn Loss: 72.61  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:28:04\n",
      "Epoch: 18  Step 2000/7031  Trn Loss: 72.86  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:30:06\n",
      "Epoch: 18  Step 3000/7031  Trn Loss: 72.87  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:32:08\n",
      "Epoch: 18  Step 4000/7031  Trn Loss: 72.73  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:34:10\n",
      "Epoch: 18  Step 5000/7031  Trn Loss: 72.73  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:36:11\n",
      "Epoch: 18  Step 6000/7031  Trn Loss: 72.79  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:38:13\n",
      "Epoch: 18  Step 7000/7031  Trn Loss: 72.74  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:40:15\n",
      "Epoch: 18  Step 7031/7031  Trn Loss: 72.75  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:40:19\n",
      "\n",
      "Epoch: 18  Trn Loss: 72.75  Val Loss: 99.92  GPU Usage: 5.27GB  Elapsed Time: 4:41:26\n",
      "\n",
      "New best val_loss: 99.92\n",
      "\n",
      "Epoch: 19  Step 1000/7031  Trn Loss: 70.51  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:43:32\n",
      "Epoch: 19  Step 2000/7031  Trn Loss: 70.73  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:45:44\n",
      "Epoch: 19  Step 3000/7031  Trn Loss: 70.61  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:47:43\n",
      "Epoch: 19  Step 4000/7031  Trn Loss: 70.65  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:49:43\n",
      "Epoch: 19  Step 5000/7031  Trn Loss: 70.70  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:51:43\n",
      "Epoch: 19  Step 6000/7031  Trn Loss: 70.72  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:53:42\n",
      "Epoch: 19  Step 7000/7031  Trn Loss: 70.80  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:55:42\n",
      "Epoch: 19  Step 7031/7031  Trn Loss: 70.80  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:55:46\n",
      "\n",
      "Epoch: 19  Trn Loss: 70.80  Val Loss: 97.49  GPU Usage: 5.27GB  Elapsed Time: 4:56:51\n",
      "\n",
      "New best val_loss: 97.49\n",
      "\n",
      "Epoch: 20  Step 1000/7031  Trn Loss: 69.29  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 4:58:52\n",
      "Epoch: 20  Step 2000/7031  Trn Loss: 69.03  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:00:51\n",
      "Epoch: 20  Step 3000/7031  Trn Loss: 68.98  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:02:51\n",
      "Epoch: 20  Step 4000/7031  Trn Loss: 69.11  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:04:50\n",
      "Epoch: 20  Step 5000/7031  Trn Loss: 69.18  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:06:49\n",
      "Epoch: 20  Step 6000/7031  Trn Loss: 69.22  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:08:48\n",
      "Epoch: 20  Step 7000/7031  Trn Loss: 69.29  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:11:04\n",
      "Epoch: 20  Step 7031/7031  Trn Loss: 69.30  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:11:09\n",
      "\n",
      "Epoch: 20  Trn Loss: 69.30  Val Loss: 98.55  GPU Usage: 5.27GB  Elapsed Time: 5:12:31\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 21  Step 1000/7031  Trn Loss: 68.06  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:14:54\n",
      "Epoch: 21  Step 2000/7031  Trn Loss: 67.75  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:17:19\n",
      "Epoch: 21  Step 3000/7031  Trn Loss: 67.89  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:19:44\n",
      "Epoch: 21  Step 4000/7031  Trn Loss: 68.03  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:22:09\n",
      "Epoch: 21  Step 5000/7031  Trn Loss: 68.07  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:24:25\n",
      "Epoch: 21  Step 6000/7031  Trn Loss: 68.02  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:26:54\n",
      "Epoch: 21  Step 7000/7031  Trn Loss: 68.03  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:29:24\n",
      "Epoch: 21  Step 7031/7031  Trn Loss: 68.03  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:29:29\n",
      "\n",
      "Epoch: 21  Trn Loss: 68.03  Val Loss: 97.03  GPU Usage: 5.27GB  Elapsed Time: 5:30:52\n",
      "\n",
      "New best val_loss: 97.03\n",
      "\n",
      "Epoch: 22  Step 1000/7031  Trn Loss: 67.08  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:33:20\n",
      "Epoch: 22  Step 2000/7031  Trn Loss: 66.89  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:35:49\n",
      "Epoch: 22  Step 3000/7031  Trn Loss: 66.89  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:38:19\n",
      "Epoch: 22  Step 4000/7031  Trn Loss: 66.91  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:40:49\n",
      "Epoch: 22  Step 5000/7031  Trn Loss: 66.87  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:43:21\n",
      "Epoch: 22  Step 6000/7031  Trn Loss: 66.87  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:45:42\n",
      "Epoch: 22  Step 7000/7031  Trn Loss: 66.87  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:48:06\n",
      "Epoch: 22  Step 7031/7031  Trn Loss: 66.87  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:48:10\n",
      "\n",
      "Epoch: 22  Trn Loss: 66.87  Val Loss: 97.91  GPU Usage: 5.27GB  Elapsed Time: 5:49:30\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 23  Step 1000/7031  Trn Loss: 65.51  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:51:54\n",
      "Epoch: 23  Step 2000/7031  Trn Loss: 65.54  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:54:17\n",
      "Epoch: 23  Step 3000/7031  Trn Loss: 65.65  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:56:41\n",
      "Epoch: 23  Step 4000/7031  Trn Loss: 65.71  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 5:59:05\n",
      "Epoch: 23  Step 5000/7031  Trn Loss: 65.85  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:01:31\n",
      "Epoch: 23  Step 6000/7031  Trn Loss: 65.87  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:03:59\n",
      "Epoch: 23  Step 7000/7031  Trn Loss: 65.85  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:06:28\n",
      "Epoch: 23  Step 7031/7031  Trn Loss: 65.86  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:06:32\n",
      "\n",
      "Epoch: 23  Trn Loss: 65.86  Val Loss: 96.91  GPU Usage: 5.27GB  Elapsed Time: 6:07:54\n",
      "\n",
      "New best val_loss: 96.91\n",
      "\n",
      "Epoch: 24  Step 1000/7031  Trn Loss: 64.43  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:10:20\n",
      "Epoch: 24  Step 2000/7031  Trn Loss: 64.47  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:12:48\n",
      "Epoch: 24  Step 3000/7031  Trn Loss: 64.67  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:15:17\n",
      "Epoch: 24  Step 4000/7031  Trn Loss: 64.57  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:17:45\n",
      "Epoch: 24  Step 5000/7031  Trn Loss: 64.69  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:20:12\n",
      "Epoch: 24  Step 6000/7031  Trn Loss: 64.80  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:22:39\n",
      "Epoch: 24  Step 7000/7031  Trn Loss: 64.86  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:25:08\n",
      "Epoch: 24  Step 7031/7031  Trn Loss: 64.86  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:25:13\n",
      "\n",
      "Epoch: 24  Trn Loss: 64.86  Val Loss: 97.34  GPU Usage: 5.27GB  Elapsed Time: 6:26:34\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 25  Step 1000/7031  Trn Loss: 63.87  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:28:59\n",
      "Epoch: 25  Step 2000/7031  Trn Loss: 63.95  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:30:59\n",
      "Epoch: 25  Step 3000/7031  Trn Loss: 63.96  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:33:00\n",
      "Epoch: 25  Step 4000/7031  Trn Loss: 64.06  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:35:00\n",
      "Epoch: 25  Step 5000/7031  Trn Loss: 64.06  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:37:00\n",
      "Epoch: 25  Step 6000/7031  Trn Loss: 64.03  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:39:00\n",
      "Epoch: 25  Step 7000/7031  Trn Loss: 64.04  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:41:00\n",
      "Epoch: 25  Step 7031/7031  Trn Loss: 64.05  LR: 1.58e-04  GPU Usage: 5.27GB  Elapsed Time: 6:41:04\n",
      "\n",
      "Epoch: 25  Trn Loss: 64.05  Val Loss: 98.24  GPU Usage: 5.27GB  Elapsed Time: 6:42:09\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 26  Step 1000/7031  Trn Loss: 60.51  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 6:44:09\n",
      "Epoch: 26  Step 2000/7031  Trn Loss: 60.80  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 6:46:09\n",
      "Epoch: 26  Step 3000/7031  Trn Loss: 60.70  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 6:48:07\n",
      "Epoch: 26  Step 4000/7031  Trn Loss: 60.64  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 6:50:05\n",
      "Epoch: 26  Step 5000/7031  Trn Loss: 60.66  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 6:52:04\n",
      "Epoch: 26  Step 6000/7031  Trn Loss: 60.59  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 6:54:02\n",
      "Epoch: 26  Step 7000/7031  Trn Loss: 60.55  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 6:56:01\n",
      "Epoch: 26  Step 7031/7031  Trn Loss: 60.54  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 6:56:04\n",
      "\n",
      "Epoch: 26  Trn Loss: 60.54  Val Loss: 94.97  GPU Usage: 5.27GB  Elapsed Time: 6:57:10\n",
      "\n",
      "New best val_loss: 94.97\n",
      "\n",
      "Epoch: 27  Step 1000/7031  Trn Loss: 59.52  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 6:59:09\n",
      "Epoch: 27  Step 2000/7031  Trn Loss: 59.34  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:01:08\n",
      "Epoch: 27  Step 3000/7031  Trn Loss: 59.34  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:03:05\n",
      "Epoch: 27  Step 4000/7031  Trn Loss: 59.48  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:05:03\n",
      "Epoch: 27  Step 5000/7031  Trn Loss: 59.43  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:07:00\n",
      "Epoch: 27  Step 6000/7031  Trn Loss: 59.46  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:08:58\n",
      "Epoch: 27  Step 7000/7031  Trn Loss: 59.47  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:10:56\n",
      "Epoch: 27  Step 7031/7031  Trn Loss: 59.46  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:10:59\n",
      "\n",
      "Epoch: 27  Trn Loss: 59.46  Val Loss: 95.17  GPU Usage: 5.27GB  Elapsed Time: 7:12:04\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 28  Step 1000/7031  Trn Loss: 58.55  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:14:02\n",
      "Epoch: 28  Step 2000/7031  Trn Loss: 58.66  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:16:00\n",
      "Epoch: 28  Step 3000/7031  Trn Loss: 58.64  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:17:58\n",
      "Epoch: 28  Step 4000/7031  Trn Loss: 58.73  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:19:57\n",
      "Epoch: 28  Step 5000/7031  Trn Loss: 58.79  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:21:55\n",
      "Epoch: 28  Step 6000/7031  Trn Loss: 58.84  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:23:52\n",
      "Epoch: 28  Step 7000/7031  Trn Loss: 58.85  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:25:50\n",
      "Epoch: 28  Step 7031/7031  Trn Loss: 58.86  LR: 5.00e-05  GPU Usage: 5.27GB  Elapsed Time: 7:25:53\n",
      "\n",
      "Epoch: 28  Trn Loss: 58.86  Val Loss: 95.00  GPU Usage: 5.27GB  Elapsed Time: 7:26:58\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 29  Step 1000/7031  Trn Loss: 57.57  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:28:56\n",
      "Epoch: 29  Step 2000/7031  Trn Loss: 57.47  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:30:53\n",
      "Epoch: 29  Step 3000/7031  Trn Loss: 57.42  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:32:51\n",
      "Epoch: 29  Step 4000/7031  Trn Loss: 57.51  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:34:48\n",
      "Epoch: 29  Step 5000/7031  Trn Loss: 57.64  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:36:45\n",
      "Epoch: 29  Step 6000/7031  Trn Loss: 57.68  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:38:43\n",
      "Epoch: 29  Step 7000/7031  Trn Loss: 57.66  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:40:40\n",
      "Epoch: 29  Step 7031/7031  Trn Loss: 57.66  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:40:44\n",
      "\n",
      "Epoch: 29  Trn Loss: 57.66  Val Loss: 94.83  GPU Usage: 5.27GB  Elapsed Time: 7:41:49\n",
      "\n",
      "New best val_loss: 94.83\n",
      "\n",
      "Epoch: 30  Step 1000/7031  Trn Loss: 57.17  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:43:47\n",
      "Epoch: 30  Step 2000/7031  Trn Loss: 57.23  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:45:45\n",
      "Epoch: 30  Step 3000/7031  Trn Loss: 57.36  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:47:43\n",
      "Epoch: 30  Step 4000/7031  Trn Loss: 57.44  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:49:41\n",
      "Epoch: 30  Step 5000/7031  Trn Loss: 57.41  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:51:39\n",
      "Epoch: 30  Step 6000/7031  Trn Loss: 57.42  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:53:37\n",
      "Epoch: 30  Step 7000/7031  Trn Loss: 57.37  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:55:34\n",
      "Epoch: 30  Step 7031/7031  Trn Loss: 57.36  LR: 1.58e-05  GPU Usage: 5.27GB  Elapsed Time: 7:55:38\n",
      "\n",
      "Epoch: 30  Trn Loss: 57.36  Val Loss: 94.97  GPU Usage: 5.27GB  Elapsed Time: 7:56:43\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "\n",
      "==================================================\n",
      "MODEL TRAINING COMPLETE\n",
      "==================================================\n",
      "\n",
      "Model Summary:\n",
      "Architecture: UNet\n",
      "Total parameters: 52,079,841\n",
      "Trainable parameters: 52,079,841\n",
      "Best validation loss: 94.8333\n",
      "Total training time: 7:56:43\n",
      "\n",
      "Model Structure:\n",
      "UNet(\n",
      "  (initial_pool): AvgPool2d(kernel_size=(14, 1), stride=(14, 1), padding=0)\n",
      "  (encoder_convs): ModuleList(\n",
      "    (0): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder_pools): ModuleList(\n",
      "    (0-4): 5 x MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (inc): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Identity()\n",
      "  )\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "\n",
      "Model summary saved to model_summary_94.8333.txt\n"
     ]
    }
   ],
   "source": [
    "# Create datasets using pre-denoised data\n",
    "dstrain = PreDenoisedSeismicDataset(\n",
    "    denoised_train_inputs, \n",
    "    denoised_train_outputs,\n",
    "    n_examples_per_file=config.get(\"n_examples_per_file\", 500)\n",
    ")\n",
    "\n",
    "dsvalid = PreDenoisedSeismicDataset(\n",
    "    denoised_valid_inputs, \n",
    "    denoised_valid_outputs,\n",
    "    n_examples_per_file=config.get(\"n_examples_per_file\", 500)\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "dltrain = DataLoader(\n",
    "    dstrain,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,  # Can shuffle now that we're not processing on-the-fly\n",
    "    pin_memory=config.get(\"pin_memory\", False),\n",
    "    drop_last=True,\n",
    "    num_workers=config.get(\"num_workers\", 0),\n",
    "    persistent_workers=config.get(\"persistent_workers\", False),\n",
    ")\n",
    "\n",
    "dlvalid = DataLoader(\n",
    "    dsvalid,\n",
    "    batch_size=4*config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    pin_memory=config.get(\"pin_memory\", False),\n",
    "    drop_last=False,\n",
    "    num_workers=config.get(\"num_workers\", 0),\n",
    "    persistent_workers=config.get(\"persistent_workers\", False),\n",
    ")\n",
    "\n",
    "# Set up device, model, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(**config[\"model\"][\"unet_params\"]).to(device)\n",
    "\n",
    "if config[\"read_weights\"] is not None:\n",
    "    print(\"Reading weights from:\", config[\"read_weights\"])\n",
    "    model.load_state_dict(torch.load(config[\"read_weights\"], weights_only=True))\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), **config[\"optimizer\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', **config[\"scheduler\"][\"params\"])\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = 10000.0\n",
    "epochs_wo_improvement = 0\n",
    "t0 = time.time()\n",
    "\n",
    "for epoch in range(1, config[\"max_epochs\"] + 1):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for step, (inputs, targets) in enumerate(dltrain):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        if step % config[\"print_freq\"] == config[\"print_freq\"] - 1 or step == len(dltrain) - 1:\n",
    "            trn_loss = np.mean(train_losses)\n",
    "            t1 = format_time(time.time() - t0)\n",
    "            free, total = torch.cuda.mem_get_info(device=0)\n",
    "            mem_used = (total - free) / 1024**3\n",
    "            lr = optimizer.param_groups[-1]['lr']\n",
    "            print(\n",
    "                f\"Epoch: {epoch:02d}  Step {step+1}/{len(dltrain)}  Trn Loss: {trn_loss:.2f}  LR: {lr:.2e}  GPU Usage: {mem_used:.2f}GB  Elapsed Time: {t1}\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    valid_losses = []\n",
    "    \n",
    "    for inputs, targets in dlvalid:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        valid_losses.append(loss.item())\n",
    "\n",
    "    t1 = format_time(time.time() - t0)\n",
    "    trn_loss = np.mean(train_losses)\n",
    "    val_loss = np.mean(valid_losses)\n",
    "\n",
    "    free, total = torch.cuda.mem_get_info(device=0)\n",
    "    mem_used = (total - free) / 1024**3\n",
    "\n",
    "    print(\n",
    "        f\"\\nEpoch: {epoch:02d}  Trn Loss: {trn_loss:.2f}  Val Loss: {val_loss:.2f}  GPU Usage: {mem_used:.2f}GB  Elapsed Time: {t1}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_wo_improvement = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"\\nNew best val_loss: {val_loss:.2f}\\n\", flush=True)\n",
    "    else:\n",
    "        epochs_wo_improvement += 1\n",
    "        print(f\"\\nEpochs without improvement: {epochs_wo_improvement}\\n\", flush=True)\n",
    "\n",
    "    if epochs_wo_improvement == config[\"es_epochs\"]:\n",
    "        break\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"Architecture: UNet\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Total training time: {format_time(time.time() - t0)}\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\nModel Structure:\")\n",
    "print(model)\n",
    "print(\"=\"*50)\n",
    "\n",
    "torch.save(model.state_dict(), f\"{best_val_loss:.4f}_model.pth\")\n",
    "\n",
    "# Create a summary text file\n",
    "summary_filename = f\"model_summary_{best_val_loss:.4f}.txt\"\n",
    "\n",
    "with open(summary_filename, 'w') as f:\n",
    "    # Write header\n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "    f.write(\"MODEL TRAINING SUMMARY\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    \n",
    "    # Write model information\n",
    "    f.write(\"MODEL INFORMATION\\n\")\n",
    "    f.write(f\"Architecture: UNet\\n\")\n",
    "    f.write(f\"Total parameters: {total_params:,}\\n\")\n",
    "    f.write(f\"Trainable parameters: {trainable_params:,}\\n\")\n",
    "    f.write(f\"Best validation loss: {best_val_loss:.4f}\\n\")\n",
    "    f.write(f\"Total training time: {format_time(time.time() - t0)}\\n\\n\")\n",
    "    \n",
    "    # Write configuration information\n",
    "    f.write(\"MODEL CONFIGURATION\\n\")\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, dict):\n",
    "            f.write(f\"{key}:\\n\")\n",
    "            for sub_key, sub_value in value.items():\n",
    "                f.write(f\"  {sub_key}: {sub_value}\\n\")\n",
    "        else:\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    # Write model structure\n",
    "    f.write(\"MODEL STRUCTURE\\n\")\n",
    "    f.write(str(model) + \"\\n\")\n",
    "    \n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "\n",
    "print(f\"\\nModel summary saved to {summary_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n",
      "Architecture: UNet\n",
      "Total parameters: 52,079,841\n",
      "Trainable parameters: 52,079,841\n",
      "Best validation loss: 210.7970\n",
      "Total training time: 0:16:14\n",
      "\n",
      "Model Structure:\n",
      "UNet(\n",
      "  (initial_pool): AvgPool2d(kernel_size=(14, 1), stride=(14, 1), padding=0)\n",
      "  (encoder_convs): ModuleList(\n",
      "    (0): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): ResidualDoubleConv(\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder_pools): ModuleList(\n",
      "    (0-4): 5 x MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (inc): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): ResidualDoubleConv(\n",
      "    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Identity()\n",
      "  )\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (conv): ResidualDoubleConv(\n",
      "        (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"Architecture: UNet\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Total training time: {format_time(time.time() - t0)}\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\nModel Structure:\")\n",
    "print(model)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-14T16:28:07.669373Z",
     "iopub.status.idle": "2025-05-14T16:28:07.669589Z",
     "shell.execute_reply": "2025-05-14T16:28:07.669495Z",
     "shell.execute_reply.started": "2025-05-14T16:28:07.669486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Inference ===============\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== Inference ===============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-14T16:28:07.670246Z",
     "iopub.status.idle": "2025-05-14T16:28:07.670565Z",
     "shell.execute_reply": "2025-05-14T16:28:07.670421Z",
     "shell.execute_reply.started": "2025-05-14T16:28:07.670405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Inference\n",
    "t0 = time.time()\n",
    "\n",
    "test_files = list(Path(\"input/test\").glob(\"*.npy\"))\n",
    "x_cols = [f\"x_{i}\" for i in range(1, 70, 2)]\n",
    "fieldnames = [\"oid_ypos\"] + x_cols\n",
    "ds = TestDataset(test_files)\n",
    "dl = DataLoader(ds, batch_size=4*config[\"batch_size\"], num_workers=4, pin_memory=False)\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "\n",
    "model.eval()\n",
    "with open(\"submission.csv\", \"wt\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for inputs, oids_test in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        with torch.inference_mode():\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        y_preds = outputs[:, 0].cpu().numpy()\n",
    "\n",
    "        for y_pred, oid_test in zip(y_preds, oids_test):\n",
    "            for y_pos in range(70):\n",
    "                row = dict(zip(x_cols, [y_pred[y_pos, x_pos] for x_pos in range(1, 70, 2)]))\n",
    "                row[\"oid_ypos\"] = f\"{oid_test}_y_{y_pos}\"\n",
    "\n",
    "                writer.writerow(row)\n",
    "\n",
    "t1 = format_time(time.time() - t0)\n",
    "print(f\"Inference Time: {t1}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11756775,
     "sourceId": 39763,
     "sourceType": "competition"
    },
    {
     "datasetId": 7253205,
     "sourceId": 11568812,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7253605,
     "sourceId": 11569667,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7253661,
     "sourceId": 11569755,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
